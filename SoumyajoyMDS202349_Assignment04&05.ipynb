{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Natural Language Processing\n",
        "* Name: Soumyajoy Kundu\n",
        "* Roll Number: MDS202349"
      ],
      "metadata": {
        "id": "5eZRH1XXuWLE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Assignment 04 and 05\n",
        "\n",
        "* Use this partial data set (sourced from Kaggle) which contains research articles related to COVID-19. (same used in Assignment 01)\n",
        "* This corpus has around 56000+ files.\n",
        "* All the instructions are followed that were mentioned in Assignment 01 - 03.\n",
        "* Build a skipgram model to generate the word embedding.\n",
        "\n",
        "**Note**:\n",
        "All fine prints from the earlier assignments apply here with respect to submission guidelines."
      ],
      "metadata": {
        "id": "S_phiW4ou2TD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsND50cou671"
      },
      "source": [
        "### Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1P30n6nTU7Lv"
      },
      "outputs": [],
      "source": [
        "import os  # For interacting with the operating system\n",
        "import re  # For regular expressions\n",
        "import time  # For measuring time\n",
        "import json  # For handling JSON files\n",
        "import zipfile  # For handling zip files\n",
        "import string  # For string manipulation\n",
        "import csv  # For handling CSV files\n",
        "import pickle  # For serializing and deserializing Python objects\n",
        "from collections import Counter  # For counting elements\n",
        "import numpy as np  # For numerical operations\n",
        "import matplotlib.pyplot as plt  # For plotting\n",
        "import math  # For mathematical functions\n",
        "from multiprocessing import Pool, Manager  # For parallel processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OrXaFD-zz4x"
      },
      "source": [
        "  * Used TPU v2-8\n",
        "  * Number of cores = 96"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv2omN8m9-Jw",
        "outputId": "001dfd6e-1cd3-4782-e834-c4e871e0ca07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "96"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tpu_num_cores = os.cpu_count()\n",
        "tpu_num_cores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzx7AOb3vs9o",
        "outputId": "7c440098-a3d5-4d2b-c2d6-f32f57737630"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files extracted to /content/pdf_json\n",
            "Time taken to unzip: 37.71924877166748 seconds\n"
          ]
        }
      ],
      "source": [
        "# Path to the zip file\n",
        "zip_file_path = '/content/pdf_json.zip'\n",
        "\n",
        "# Path where the file is extracted\n",
        "extract_dir = '/content/pdf_json'\n",
        "\n",
        "start = time.time()\n",
        "# Creating the directory if it doesn't exist\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Files extracted to {extract_dir}\")\n",
        "print(f\"Time taken to unzip: {end-start} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvV4Eo7JR9BI",
        "outputId": "86edde37-c4b1-4e09-9917-21c7628dbb6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total JSON files extracted: 56528\n",
            "First 10 files: ['202383e9c79c6dac9c6de7622681a2b2fdd699b6.json', '49861eebbc323ac1fda5c90a3f25b755300b7413.json', '3ba5a8bec872feebb62f6a1f384690ba1cd63a8b.json', '1450545d1da21d84ec1c78140e28137d11053826.json', '5cc7d19d8c064e59978daa0699ca18d5b139b0db.json', '1f7f3e09db31be0bc73e921a1034ec9de0d52ebe.json', '1fa4e53e298871ed4d6c9ec3f471cc5d49d20acf.json', '564cc276d915ea2b85434de9ea2427c41ca76bdd.json', '5a2aa19ff63d93bcc65037b428235a1f6a337b19.json', '2c29ff48c88939e57b87ce996f8769b37b386122.json']\n"
          ]
        }
      ],
      "source": [
        "# List a few files to confirm extraction\n",
        "json_files = [f for f in os.listdir('/content/pdf_json/pdf_json') if f.endswith('.json')]\n",
        "\n",
        "print(f\"Total JSON files extracted: {len(json_files)}\")\n",
        "print(\"First 10 files:\", json_files[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment 04"
      ],
      "metadata": {
        "id": "NnbwxR1x5YYu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 1**: Use the COVID-19 corpus\n",
        "* Extract all the abstracts from the COVID-19 text files and use them as the corpus.\n",
        "* Ensure that you create\n",
        "a vocabulary of around 10,000 words."
      ],
      "metadata": {
        "id": "Uxyo4fAFtfem"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--l8ITGVvNeO"
      },
      "source": [
        "\n",
        "* Extract the text content from the JSON-encoded data set and create a\n",
        "text corpus.\n",
        "* You may use any JSON library to extract the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7sV_JUuSXQT"
      },
      "outputs": [],
      "source": [
        "def json2text(filename):\n",
        "    '''\n",
        "    Converts a JSON file to text.\n",
        "    '''\n",
        "    # Construct the full file path\n",
        "    filepath = os.path.join('/content/pdf_json/pdf_json', filename)  # Add the directory path\n",
        "\n",
        "    with open(filepath, encoding='latin-1') as file: # Use filepath instead of filename\n",
        "        if filename.endswith('.json'):\n",
        "            paper_content = json.load(file)\n",
        "    abstract = \"\"\n",
        "    title = \"\"\n",
        "\n",
        "    # get the paper_id\n",
        "    paper_id = paper_content['paper_id']\n",
        "\n",
        "    # get the title\n",
        "    if 'title' in paper_content:\n",
        "      title = paper_content['title']\n",
        "\n",
        "    # get the abstract\n",
        "    if 'abstract' in paper_content:\n",
        "      for abs in paper_content['abstract']:\n",
        "          abstract = abstract + abs['text']\n",
        "\n",
        "    # case-folding (all converted to lower case)\n",
        "    return abstract.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hd_6F269aXze"
      },
      "outputs": [],
      "source": [
        "def save_text_to_file(text, filename, output_dir):\n",
        "    \"\"\"\n",
        "    Saves the given text to a file in the specified output directory.\n",
        "    \"\"\"\n",
        "    # Ensure the output directory exists\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Define the path to save the text file\n",
        "    text_filename = os.path.join(output_dir, f\"{filename}.txt\")\n",
        "\n",
        "    # Write the text to the file\n",
        "    with open(text_filename, 'w', encoding='utf-8') as file:\n",
        "        file.write(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqnjMtQET35J"
      },
      "outputs": [],
      "source": [
        "def process_json_file(json_file, output_dir):\n",
        "    \"\"\"\n",
        "    Processes a single JSON file: extracts text and saves it to a file.\n",
        "    \"\"\"\n",
        "    text = json2text(json_file)\n",
        "\n",
        "    # Extract the base filename (without extension) to use as the text file name\n",
        "    base_filename = os.path.splitext(os.path.basename(json_file))[0]\n",
        "\n",
        "    # Save the extracted text to a file\n",
        "    save_text_to_file(text, base_filename, output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dyb_dEQ5aiW_"
      },
      "outputs": [],
      "source": [
        "def extract_texts(json_files, output_dir):\n",
        "    \"\"\"\n",
        "    Extracts text content from a list of JSON files in parallel and saves each text\n",
        "    into a separate file within the specified output directory.\n",
        "    \"\"\"\n",
        "    cpu_count = os.cpu_count()\n",
        "    pool = Pool(processes=cpu_count)\n",
        "\n",
        "    # Using starmap to pass both json_file and output_dir to process_json_file\n",
        "    pool.starmap(process_json_file, [(json_file, output_dir) for json_file in json_files])\n",
        "\n",
        "    pool.close()\n",
        "    pool.join()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t541FljHd1W1",
        "outputId": "36a46f38-5d77-4ad1-a2c2-decc7594bf3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All json files are converted to text files containing abstracts...\n",
            "Time taken to extract texts: 1.6233949661254883 seconds\n"
          ]
        }
      ],
      "source": [
        "# Path to create a folder where the json to text files will be kept.\n",
        "output_dir = '/content/abstracts'\n",
        "\n",
        "start = time.time()\n",
        "extract_texts(json_files, output_dir)\n",
        "end = time.time()\n",
        "\n",
        "print(\"All json files are converted to text files containing abstracts...\")\n",
        "print(f\"Time taken to extract texts: {end-start} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVCaTskavYzi"
      },
      "source": [
        "#### Text Preprocessing\n",
        "* Develop your pre-processing steps and order of steps.\n",
        "* Some examples: case-folding, removal of numbers, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZEVOedSKfe6"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries for NLP Tasks\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euIVL20UK03u",
        "outputId": "0ec91f0f-6aa8-4778-80e3-f8e37785cf53"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Downloading Packages\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyaAl1fZ0Ksq",
        "outputId": "eb797d0b-df9e-4b11-a5a6-5ccf74f4bbf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Downloading pyspellchecker-0.8.1-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.8.1\n"
          ]
        }
      ],
      "source": [
        "pip install pyspellchecker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sZ6YMNK0TKC"
      },
      "outputs": [],
      "source": [
        "from spellchecker import SpellChecker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSpYBDGeKktH"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def remove_stopwords(text, lang_stopwords):\n",
        "    \"\"\"\n",
        "    Removes stopwords from the given text.\n",
        "    :param text: The input text.\n",
        "    :param lang_stopwords: Set of stopwords to be removed.\n",
        "    :return: The text with stopwords removed.\n",
        "    \"\"\"\n",
        "    words = text.split()\n",
        "    return ' '.join([word for word in words if word not in lang_stopwords])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1zpLnJKVO1J"
      },
      "outputs": [],
      "source": [
        "def preprocess_file(filepath, output_dir):\n",
        "    \"\"\"\n",
        "    Preprocesses the text content of a single file by performing case-folding, removing numbers, and punctuation.\n",
        "    Saves the preprocessed text to a new file in the output directory.\n",
        "    Includes additional preprocessing steps based on user specifications.\n",
        "    \"\"\"\n",
        "    with open(filepath, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "\n",
        "    # 1. Remove non-ascii characters\n",
        "    text = text.encode('ascii', errors='ignore').decode()\n",
        "\n",
        "    # 2. Remove [numbers] in this format\n",
        "    text = re.sub(r'\\[\\d+\\]', '', text)\n",
        "\n",
        "    # 3. Remove punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # 3. Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # 4. Remove non-alphanumeric characters\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "\n",
        "    # 5. Case folding (convert to lowercase)\n",
        "    text = text.lower()\n",
        "\n",
        "    # 6. Remove single-letter words (e.g., 'a', 'b')\n",
        "    text = re.sub(r'\\b[a-z]\\b', '', text)\n",
        "\n",
        "    # 7. Remove stopwords (English, German, French)\n",
        "    stop_words = set(stopwords.words('english')) | set(stopwords.words('german')) | set(stopwords.words('french'))\n",
        "    text = remove_stopwords(text, stop_words)\n",
        "\n",
        "    # 8. Remove any email id, URL, or number with more than 9 digits\n",
        "    text = re.sub(r'\\S+@\\S+', '', text)  # Remove email addresses\n",
        "    text = re.sub(r'http\\S+|www\\S+', '', text)  # Remove URLs\n",
        "    text = re.sub(r'\\b\\d{10,}\\b', '', text)  # Remove numbers greater than 9 digits\n",
        "\n",
        "    # 9. Convert \"$\" to \"dollars\"\n",
        "    text = text.replace('$', 'dollars')\n",
        "\n",
        "    # 10. Remove words longer than 20 characters\n",
        "    text = ' '.join([word for word in text.split() if len(word) <= 20])\n",
        "\n",
        "    # 11. Spell check and remove words with incorrect spelling\n",
        "    spell = SpellChecker()\n",
        "    words = text.split()\n",
        "    misspelled = spell.unknown(words)\n",
        "    text = ' '.join([word for word in words if word not in misspelled])\n",
        "\n",
        "    # 12. Remove extra spaces created by the removal of unwanted characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # Save the preprocessed text to the output directory\n",
        "    filename = os.path.basename(filepath)\n",
        "    output_path = os.path.join(output_dir, filename)\n",
        "    with open(output_path, 'w', encoding='utf-8') as output_file:\n",
        "        output_file.write(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veLDw2nAcVQW"
      },
      "outputs": [],
      "source": [
        "def preprocess_corpus_multiprocessing(input_dir, output_dir):\n",
        "    \"\"\"\n",
        "    Preprocesses all text files in the specified directory using multiprocessing and saves them to the output directory.\n",
        "    \"\"\"\n",
        "    # Create the output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Get the list of all text files in the input directory\n",
        "    text_files = [os.path.join(input_dir, filename) for filename in os.listdir(input_dir) if filename.endswith('.txt')]\n",
        "\n",
        "    # Use multiprocessing to preprocess the files\n",
        "    cpu_count = os.cpu_count()\n",
        "    with Pool(processes=cpu_count) as pool:\n",
        "        pool.starmap(preprocess_file, [(filepath, output_dir) for filepath in text_files])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prbZXFtm1DdY",
        "outputId": "ea4c7aac-c499-487f-f40b-4ed43172bb6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text Preprocessing Done!\n",
            "Time taken to preprocess: 177.95962810516357 seconds\n"
          ]
        }
      ],
      "source": [
        "# Path for converted text files\n",
        "input_directory = '/content/abstracts'\n",
        "\n",
        "# Path to create a folder for the Preprocessed text files\n",
        "output_directory = '/content/abstracts_preprocessed'\n",
        "\n",
        "start = time.time()\n",
        "preprocess_corpus_multiprocessing(input_directory, output_directory)\n",
        "end = time.time()\n",
        "\n",
        "print(\"Text Preprocessing Done!\")\n",
        "print(f\"Time taken to preprocess: {end-start} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the preprocessed corpus of abstracts in a .txt file."
      ],
      "metadata": {
        "id": "OgRaRT-3q6UE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XAfQ8YAwzr6"
      },
      "outputs": [],
      "source": [
        "combined_text = \"\"\n",
        "for file in os.listdir('/content/abstracts_preprocessed'):\n",
        "    if file.endswith('.txt'):\n",
        "        with open(os.path.join('/content/abstracts_preprocessed', file), 'r') as f:\n",
        "            with open('combined_abstracts_prep.txt', 'a') as combined_file:\n",
        "                combined_file.write(f.read() + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "As3b8ivW03kC"
      },
      "source": [
        "#### Tokenizing the corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPbxycsoHj66"
      },
      "outputs": [],
      "source": [
        "def process_file(file_path):\n",
        "    \"\"\"\n",
        "    Process a single file to extract tokens and vocabulary.\n",
        "    Returns a tuple of tokens and unique vocabulary from the file.\n",
        "    \"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "    tokens = word_tokenize(text)\n",
        "    vocabulary = set(tokens)\n",
        "    return tokens, vocabulary\n",
        "\n",
        "def process_corpus_tokens(input_dir):\n",
        "    \"\"\"\n",
        "    Processes all files in the input directory to extract tokens and vocabulary\n",
        "    in parallel using multiple processes. Returns the complete list of tokens\n",
        "    and unique vocabulary.\n",
        "    \"\"\"\n",
        "    # Get the list of all preprocessed text files in the input directory\n",
        "    text_files = [os.path.join(input_dir, filename) for filename in os.listdir(input_dir) if filename.endswith('.txt')]\n",
        "\n",
        "    # Use a pool of workers to process files in parallel\n",
        "    cpu_count = os.cpu_count()\n",
        "    with Pool(cpu_count) as pool:\n",
        "        results = pool.map(process_file, text_files)\n",
        "\n",
        "    # Aggregate tokens and vocabulary from all files\n",
        "    all_tokens = []\n",
        "    vocabulary = set()\n",
        "    for tokens, vocab in results:\n",
        "        all_tokens.extend(tokens)\n",
        "        vocabulary.update(vocab)\n",
        "\n",
        "    # Return all tokens and vocabulary\n",
        "    return all_tokens, list(vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iBRS34VK-5K",
        "outputId": "c70322df-7136-4937-a217-fd190d66b42f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenization Done!\n",
            "Time taken to preprocess: 3.6375629901885986 seconds\n"
          ]
        }
      ],
      "source": [
        "input_dir = '/content/abstracts_preprocessed'\n",
        "\n",
        "start = time.time()\n",
        "tokens, vocab = process_corpus_tokens(input_dir)\n",
        "end = time.time()\n",
        "\n",
        "print(\"Tokenization Done!\")\n",
        "print(f\"Time taken to preprocess: {end-start} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuvSguFULlUZ",
        "outputId": "b3cd9d63-539c-4e86-ff80-65b2414b306e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(33669, 4308442)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(vocab), len(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaqF9n841YWw"
      },
      "source": [
        "* Storing the $\\texttt{tokens}$ and $\\texttt{vocab}$ in pickle ($\\texttt{.pkl}$) file for future use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWB2SzEJW16Q"
      },
      "outputs": [],
      "source": [
        "with open('tokens_abs.pkl', 'wb') as f:\n",
        "        pickle.dump(tokens, f)\n",
        "\n",
        "with open('vocab_abs.pkl', 'wb') as f:\n",
        "        pickle.dump(vocab, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PpgOr7z16wO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from multiprocessing import Pool, cpu_count\n",
        "from nltk.probability import FreqDist\n",
        "from functools import partial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTMC0Pn_19LN"
      },
      "outputs": [],
      "source": [
        "def filter_tokens(tokens, vocab_red):\n",
        "    \"\"\"\n",
        "    Filters the tokens based on the reduced vocabulary.\n",
        "    \"\"\"\n",
        "    return [token for token in tokens if token in vocab_red]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2Hs4fHJ2Atr"
      },
      "outputs": [],
      "source": [
        "def get_reduced_vocab(tokens, n=7000):\n",
        "    \"\"\"\n",
        "    Computes the frequency distribution of tokens and returns the reduced vocabulary\n",
        "    containing the top 'n' most common words.\n",
        "    \"\"\"\n",
        "    freq_dist = FreqDist(tokens)\n",
        "    vocab_red = [word for word, _ in freq_dist.most_common(n)]\n",
        "    return vocab_red"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9MIOAe02Jgy"
      },
      "outputs": [],
      "source": [
        "def parallel_filter(tokens, vocab_red):\n",
        "    \"\"\"\n",
        "    Filters tokens in parallel using multiple processes.\n",
        "    \"\"\"\n",
        "    # Split the tokens list into chunks to distribute among processes\n",
        "    num_chunks = os.cpu_count()\n",
        "    chunk_size = len(tokens) // num_chunks\n",
        "\n",
        "    # Create chunks of tokens\n",
        "    token_chunks = [tokens[i:i + chunk_size] for i in range(0, len(tokens), chunk_size)]\n",
        "\n",
        "    # Use a pool of workers to filter tokens in parallel\n",
        "    with Pool(num_chunks) as pool:\n",
        "        # Use 'partial' to pass the reduced vocab to each worker\n",
        "        results = pool.map(partial(filter_tokens, vocab_red=vocab_red), token_chunks)\n",
        "\n",
        "    # Flatten the results\n",
        "    filtered_tokens = [token for sublist in results for token in sublist]\n",
        "\n",
        "    return filtered_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6vPJW8MMLVR"
      },
      "outputs": [],
      "source": [
        "def limit_vocab_in_parallel(tokens):\n",
        "    \"\"\"\n",
        "    Main function to reduce vocabulary and filter tokens using multiprocessing.\n",
        "    \"\"\"\n",
        "    # Get the reduced vocabulary\n",
        "    vocab_red = get_reduced_vocab(tokens, n=10000)\n",
        "\n",
        "    # Filter tokens in parallel\n",
        "    tokens_red = parallel_filter(tokens, vocab_red)\n",
        "\n",
        "    return tokens_red, vocab_red"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2M8NvhPQJFP",
        "outputId": "6c0a5c63-3794-44b1-ac21-644bae667cec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary Reduction Done!\n",
            "Time taken to reduce vocabulary to 10K words: 6.9913763999938965 seconds\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "tokens_red, vocab_red = limit_vocab_in_parallel(tokens)\n",
        "end = time.time()\n",
        "\n",
        "print(\"Vocabulary Reduction Done!\")\n",
        "print(f\"Time taken to reduce vocabulary to 10K words: {end-start} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCV0d76e2dZx"
      },
      "source": [
        "* Number of words in reduced voabulary and the respective count of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnYcEZlv_uNZ",
        "outputId": "17ea9f6f-9615-45d3-a230-893f9dec9f59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 4175079)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(vocab_red), len(tokens_red)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYUqcajy2oTD"
      },
      "source": [
        "* Storing the $\\texttt{tokens_red}$ and $\\texttt{vocab_red}$ in pickle ($\\texttt{.pkl}$) file for future use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uAZAu9gYeqO"
      },
      "outputs": [],
      "source": [
        "with open('tokens_red.pkl', 'wb') as f:\n",
        "        pickle.dump(tokens_red, f)\n",
        "\n",
        "with open('vocab_red.pkl', 'wb') as f:\n",
        "        pickle.dump(vocab_red, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VS_XPHlyo9i",
        "outputId": "3474ce71-6d2d-403f-f96a-1240dc9f9e42"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('patients', 32977),\n",
              " ('virus', 21818),\n",
              " ('infection', 20890),\n",
              " ('study', 20234),\n",
              " ('disease', 19712),\n",
              " ('data', 16289),\n",
              " ('viral', 16086),\n",
              " ('health', 16074),\n",
              " ('results', 15564),\n",
              " ('respiratory', 15246)]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "Counter(tokens_red).most_common(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 2**: Construct One-Hot Vectors (OHVs)\n",
        "You may construct each one on the fly (just in time) during training, or you can pre-create and store\n",
        "them in memory (volatile or non-volatile). If you associate numerical indexes with the vocabulary, you can\n",
        "generate each OHV on demand during training.\n"
      ],
      "metadata": {
        "id": "ruHlrNdDtPCO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DO8Qk2VxzuIb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from multiprocessing import Pool\n",
        "\n",
        "# Create an index mapping (word to index)\n",
        "word_to_index = {word: idx for idx, word in enumerate(vocab_red)}\n",
        "vocab_size = len(vocab_red)\n",
        "\n",
        "def generate_one_hot_vector(word_idx):\n",
        "    \"\"\"\n",
        "    Generate a one-hot vector for a given word index.\n",
        "    \"\"\"\n",
        "    one_hot = np.zeros(vocab_size, dtype=int)\n",
        "    one_hot[word_idx] = 1\n",
        "    return one_hot\n",
        "\n",
        "def process_word(word):\n",
        "    \"\"\"\n",
        "    Process a single word to generate its one-hot vector.\n",
        "    \"\"\"\n",
        "    word_idx = word_to_index[word]\n",
        "    return generate_one_hot_vector(word_idx)\n",
        "\n",
        "def generate_one_hot_vectors_parallel(vocab):\n",
        "    \"\"\"\n",
        "    Generate one-hot vectors for the entire vocabulary in parallel.\n",
        "    \"\"\"\n",
        "    with Pool() as pool:\n",
        "        one_hot_vectors = pool.map(process_word, vocab)\n",
        "    return np.array(one_hot_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gfa6xN2Oz28h",
        "outputId": "663279de-554a-451f-8c62-7010289a3cc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-hot Vector Generation Done!\n",
            "Time taken to generate one-hot vectors: 5.186119556427002 seconds\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "# Generate the one-hot vectors for the entire vocabulary\n",
        "one_hot_vectors = generate_one_hot_vectors_parallel(vocab_red)\n",
        "end = time.time()\n",
        "\n",
        "print(\"One-hot Vector Generation Done!\")\n",
        "print(f\"Time taken to generate one-hot vectors: {end-start} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2dmP8lPz-3Z",
        "outputId": "bd5e9193-0640-484f-a0cf-39741b107a2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word: case, One-Hot Vector: 1\n"
          ]
        }
      ],
      "source": [
        "# Verify one example\n",
        "print(f\"Word: {vocab_red[100]}, One-Hot Vector: {one_hot_vectors[100].sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mWXpMPw0tYu",
        "outputId": "0cf6fdd3-1de0-48c0-a13d-ba0ca9b7667f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One-hot vectors saved successfully!\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Save the one-hot vectors to a pickle file\n",
        "with open('one_hot_vectors.pkl', 'wb') as file:\n",
        "    pickle.dump(one_hot_vectors, file)\n",
        "\n",
        "print(\"One-hot vectors saved successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Filtering Corpus based on reduced Vocabulary"
      ],
      "metadata": {
        "id": "B4dIgn0Qwl9f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ip0O9FzjRID_"
      },
      "outputs": [],
      "source": [
        "with open('tokens_red.pkl', 'rb') as f:\n",
        "    tokens_red = pickle.load(f)\n",
        "\n",
        "with open('vocab_red.pkl', 'rb') as f:\n",
        "    vocab_red = pickle.load(f)\n",
        "\n",
        "with open('one_hot_vectors.pkl', 'rb') as f:\n",
        "    one_hot_vectors = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_corpus(file_path):\n",
        "    \"\"\"\n",
        "    Load a corpus from a text file, where each line is a sentence.\n",
        "    \"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        corpus = f.readlines()  # Read each line (assumed to be one sentence per line)\n",
        "    return [sentence.strip().split() for sentence in corpus]  # Tokenize each sentence into words\n",
        "\n",
        "\n",
        "def save_corpus(corpus, file_path):\n",
        "    \"\"\"\n",
        "    Save a corpus to a text file, where each line is a sentence.\n",
        "    \"\"\"\n",
        "    with open(file_path, 'w', encoding='utf-8') as f:\n",
        "        for sentence in corpus:\n",
        "            f.write(' '.join(sentence) + '\\n')  # Join tokens into sentences and write"
      ],
      "metadata": {
        "id": "9HslYjNfwBsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_sentences(sentences, top_words):\n",
        "    \"\"\"\n",
        "    Filter sentences based on the top words.\n",
        "    \"\"\"\n",
        "    filtered_sentences = []\n",
        "    for sentence in sentences:\n",
        "        filtered_sentence = [word for word in sentence if word in top_words]\n",
        "        if filtered_sentence:  # Only add non-empty sentences\n",
        "            filtered_sentences.append(filtered_sentence)\n",
        "    return filtered_sentences\n",
        "\n",
        "\n",
        "def parallel_filter_corpus(corpus, top_words, num_workers=os.cpu_count()):\n",
        "    \"\"\"\n",
        "    Filter the corpus in parallel using multiple processes.\n",
        "    \"\"\"\n",
        "    # Split the corpus into chunks for each worker\n",
        "    chunk_size = len(corpus) // num_workers\n",
        "    corpus_chunks = [corpus[i:i + chunk_size] for i in range(0, len(corpus), chunk_size)]\n",
        "\n",
        "    # Create a pool of workers\n",
        "    pool = mp.Pool(processes=num_workers)\n",
        "\n",
        "    # Use the pool to filter each chunk of the corpus in parallel\n",
        "    results = pool.starmap(filter_sentences, [(chunk, top_words) for chunk in corpus_chunks])\n",
        "\n",
        "    # Close the pool\n",
        "    pool.close()\n",
        "    pool.join()\n",
        "\n",
        "    # Flatten the list of results\n",
        "    filtered_corpus = [sentence for result in results for sentence in result]\n",
        "\n",
        "    return filtered_corpus"
      ],
      "metadata": {
        "id": "vkjPvOcQwECA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing as mp\n",
        "\n",
        "# File paths\n",
        "input_file = '/content/combined_abstracts_prep.txt'  # Input corpus file\n",
        "output_file = '/content/filtered_corpus.txt'         # Output file for filtered corpus\n",
        "\n",
        "# Load the corpus from the text file\n",
        "corpus = load_corpus(input_file)\n",
        "\n",
        "# Run the parallel filtering\n",
        "updated_corpus = parallel_filter_corpus(corpus, vocab_red, num_workers=4)\n",
        "\n",
        "# Save the updated corpus to a new file\n",
        "save_corpus(updated_corpus, output_file)"
      ],
      "metadata": {
        "id": "nC-q7e0rv8yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 3**: Describe Your Architecture\n",
        "\n"
      ],
      "metadata": {
        "id": "TC44Cba6uNyO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Class Definition**\n",
        "**Class**: `SkipGramNegSamp(nn.Module)`\n",
        "\n",
        "This class inherits from `nn.Module` in PyTorch. It defines the Skip-Gram model with negative sampling, which is designed to learn word embeddings by predicting context words from target words while minimizing loss for negative samples."
      ],
      "metadata": {
        "id": "liGkaxZ_7p68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Constructor**\n",
        "**Method**: `__init__(self, vocab_size, embedding_dim)`\n",
        "\n",
        "**Parameters**:\n",
        "- `vocab_size`: Size of the vocabulary, representing the number of unique words in the dataset.\n",
        "- `embedding_dim = 128`: Dimensionality of the word embeddings, specifying the size of the dense vectors for each word.\n",
        "\n",
        "\n",
        "**Components**:\n",
        "- `self.in_embedding`: Embedding layer for target words. Maps each word in the vocabulary to an `embedding_dim`-dimensional vector.\n",
        "- `self.out_embedding`: Embedding layer for context words. Similar to `in_embedding`, but used for context predictions.\n"
      ],
      "metadata": {
        "id": "eB53g6Lb73wC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Forward Method**\n",
        "\n",
        "**Method**: `forward(self, target, context, negative_samples)`\n",
        "\n",
        "**Input**:\n",
        "- `target`: Tensor of target word indices (shape: `(batch_size,)`).\n",
        "- `context`: Tensor of context word indices (shape: `(batch_size,)`).\n",
        "- `negative_samples`: Tensor of negative word indices (shape: `(batch_size, num_negative_samples = 5)`).\n",
        "\n",
        "**Process**:\n",
        "- Retrieves the target word embeddings from `self.in_embedding`.\n",
        "- Retrieves the context word embeddings from `self.out_embedding`.\n",
        "- Computes the **positive score** as the dot product of target and context word embeddings.\n",
        "- Computes the **negative scores** by taking the dot product of target word embeddings with negative samples.\n",
        "\n",
        "**Output**:\n",
        "- `positive_score`: A tensor representing the similarity score for target-context pairs.\n",
        "- `negative_scores`: A tensor representing similarity scores for negative samples."
      ],
      "metadata": {
        "id": "yXxHviFg71d7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **Training Objective**\n",
        "The model is trained using **negative sampling**, where:\n",
        "- **Positive score** represents the likelihood of the target word being related to the context word.\n",
        "- **Negative scores** are used to minimize the likelihood of random (unrelated) words appearing as the context.\n",
        "\n",
        "The loss function used is `BCEWithLogitsLoss`, which applies binary cross-entropy between the predicted scores and the actual labels (positive context or negative samples). This architecture is optimized using **Stochastic Gradient Descent (SGD)**. Negative sampling reduces computational complexity by considering only a small number of incorrect (negative) word pairs, instead of calculating predictions for all words in the vocabulary."
      ],
      "metadata": {
        "id": "aULYPFST8CZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from tqdm.notebook import tqdm\n",
        "import random"
      ],
      "metadata": {
        "id": "OB9-NQgJKBlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load the preprocessed text data\n",
        "with open('/content/filtered_corpus.txt', 'r') as file:\n",
        "    corpus = file.readlines()\n",
        "\n",
        "# Preprocess the corpus\n",
        "corpus = [line.strip().split() for line in corpus if line.strip()]\n",
        "\n",
        "# Flatten the corpus to a list of words\n",
        "flat_corpus = [word for sentence in corpus for word in sentence]\n",
        "\n",
        "# Create a vocabulary and a mapping from words to indices\n",
        "word_counts = Counter(flat_corpus)\n",
        "vocabulary = sorted(word_counts.keys())\n",
        "vocab_size = len(vocabulary)\n",
        "word_to_idx = {word: idx for idx, word in enumerate(vocabulary)}"
      ],
      "metadata": {
        "id": "RiDm6FeqUzQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "embedding_dim = 128  # Dimension of word embeddings\n",
        "window_size = 2      # Context window size\n",
        "num_negative_samples = 5  # Number of negative samples per positive example\n",
        "num_epochs = 5       # Number of epochs\n",
        "learning_rate = 0.01 # Learning rate\n",
        "batch_size = 64      # Batch size for training"
      ],
      "metadata": {
        "id": "jAU0qu85KH1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_training_data(corpus, window_size):\n",
        "    \"\"\"\n",
        "    Generate training data for the Skip-Gram model.\n",
        "    \"\"\"\n",
        "    training_pairs = []\n",
        "    for sentence in corpus:\n",
        "        indices = [word_to_idx[word] for word in sentence]\n",
        "        for i, word_idx in enumerate(indices):\n",
        "            # Create pairs of (target, context)\n",
        "            start = max(0, i - window_size)\n",
        "            end = min(len(indices), i + window_size + 1)\n",
        "            for j in range(start, end):\n",
        "                if i != j:  # Skip the target word itself\n",
        "                    training_pairs.append((word_idx, indices[j]))\n",
        "    return training_pairs"
      ],
      "metadata": {
        "id": "UzodLnbhKLLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_pairs = generate_training_data(corpus, window_size)"
      ],
      "metadata": {
        "id": "lrYXyihzaE_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SkipGramNegSamp(nn.Module):\n",
        "    \"\"\"\n",
        "    Skip-Gram model with negative sampling.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        \"\"\"\n",
        "        Initialize the SkipGramNegSamp model.\n",
        "        \"\"\"\n",
        "        super(SkipGramNegSamp, self).__init__()\n",
        "        self.in_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.out_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    def forward(self, target, context, negative_samples):\n",
        "        \"\"\"\n",
        "        Forward pass of the SkipGramNegSamp model.\n",
        "        \"\"\"\n",
        "        # Get the target word embedding\n",
        "        target_embedding = self.in_embedding(target)  # Shape: (batch_size, embedding_dim)\n",
        "\n",
        "        # Positive score for the context word\n",
        "        context_embedding = self.out_embedding(context)  # Shape: (batch_size, embedding_dim)\n",
        "        positive_score = torch.sum(target_embedding * context_embedding, dim=1)  # Dot product\n",
        "\n",
        "        # Negative scores for the negative samples\n",
        "        negative_embeddings = self.out_embedding(negative_samples)  # Shape: (batch_size, num_negative_samples, embedding_dim)\n",
        "        negative_scores = torch.bmm(negative_embeddings, target_embedding.unsqueeze(2)).squeeze(2)  # Dot product\n",
        "\n",
        "        return positive_score, negative_scores"
      ],
      "metadata": {
        "id": "BH6d-leOKReQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_batches(training_data, batch_size):\n",
        "    \"\"\"\n",
        "    Create batches of training data.\n",
        "    \"\"\"\n",
        "    random.shuffle(training_data)  # Shuffle the data before batching\n",
        "    batches = [training_data[i:i + batch_size] for i in range(0, len(training_data), batch_size)]\n",
        "    return batches"
      ],
      "metadata": {
        "id": "ddWqxqaAKYFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 6**: Use Negative Sampling"
      ],
      "metadata": {
        "id": "h3XSjpPAKy4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_negative_words(batch_size, num_negative_samples, vocab_size, exclude):\n",
        "    \"\"\"\n",
        "    Sample negative words (indices) that are not in the positive context.\n",
        "    \"\"\"\n",
        "    negative_samples = []\n",
        "    for _ in range(batch_size):\n",
        "        negatives = []\n",
        "        while len(negatives) < num_negative_samples:\n",
        "            neg_sample = random.randint(0, vocab_size - 1)\n",
        "            if neg_sample not in exclude:  # Ensure the negative sample is not in the context\n",
        "                negatives.append(neg_sample)\n",
        "        negative_samples.append(negatives)\n",
        "    return torch.tensor(negative_samples, dtype=torch.long).to(device)"
      ],
      "metadata": {
        "id": "CE_FbVpfKTdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 4**: Use Stochastic Gradient Descent (SGD)"
      ],
      "metadata": {
        "id": "mvSjmPBPK8GB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model, loss function, and optimizer\n",
        "model = SkipGramNegSamp(vocab_size, embedding_dim).to(device)  # Move model to GPU\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate) # Stochastic Gradient Descent\n",
        "loss_fn = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy loss for positive/negative samples"
      ],
      "metadata": {
        "id": "WQUGhWYMKfNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training the SkipGram Model"
      ],
      "metadata": {
        "id": "XPsmq3V15u-z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264,
          "referenced_widgets": [
            "8f9a449224ca4c2488e407d8a46e4f27",
            "2a32789d89c148a6a16287bc61398f79",
            "35348f825f71479594119b0dce150398",
            "cdc8f048c3064a808ec5f0fc9fbe1c25",
            "5ef109780a984ee99db3700cd0f6f65f",
            "55aba166b26f4a9f83c7d88ad5ce09fa",
            "adc1e37e05bd4aac9f37343e2ce3be1d",
            "28b291e837fc4a41a0da4f636e9014ff",
            "edc8e9a95ca645fa8f9c8bd3f2a04f98",
            "200958a011b34f85ae98696e7975c648",
            "bc6c8bf0980b4556a8823247bb48bc77",
            "aabeea0515f1436bb25c663560e7c6e1",
            "43dbd18ed31b4b0c8e80815d77574cd6",
            "c82dd447b3244a06af299c3285957de5",
            "cf168ba501254744ae93ee51ead368f2",
            "fe07e522c43d41879075bc465b35e78d",
            "d7f7be351c45420dbedc4fc689701b19",
            "170abdda99ac479bb02cf78bcbea4a94",
            "fd91c0471f8a4576a682c23a482e59d8",
            "dc53073205664039a1338f227a679560",
            "a8309b566a374b04ac12088915ec7fbd",
            "84cf675694cf4bad90a108879af3b93e",
            "f210aa1dc6d640359cfd689c326a9627",
            "368859871e6040bd953802d4ee096daa",
            "713c2f600a60472393db4f3a71cc3336",
            "6b07fca380184d05b07385b75c0159be",
            "10602755247f4573bcd5b1b6a8916413",
            "abbf4a1f0c4649eeb8691cabab47073c",
            "6fe7b583862e49fd8933cca4fcb9ec17",
            "42e7730cb0a545358dc83930e2d3840d",
            "5b16715294354513bbe89fcef1567339",
            "b18a6d7f6b5e48909f12ca47aaca8de9",
            "f95331765b7c470c923b115d99f7fd81",
            "9f66748d7eee4613b6a847b42ca21456",
            "e75e069184f340a4b073ceeca31717cf",
            "da1a773083bb4695bf4a735eef1fb41d",
            "06dc379e79104e7eaa46d5088035cb40",
            "c24826cf41464d42b556dd57eed82715",
            "5e19f9401686402db18564a59aaf311c",
            "4abc1b3b383442a79eff1a635752d9c7",
            "e6d2148c5f5146ebbf7b620b48092ce4",
            "06845a1e3dbc4cf89f92500e1761f645",
            "24012e6f315b4694aae3f169a0e6575f",
            "066a17378f6f4e9393febeeace2049c3",
            "1be81ff7d3b9443e9d0b688f1cb3e21a",
            "34b7ba799a064e13bb5ba41f47a40861",
            "904ce098015247b296c203d06ec99257",
            "4daba4c1b4b74683a7df024bd55d2290",
            "92ccccb810e14162afb8d78ff79ada8c",
            "ac9aeba36c904c55bd1bb84ba04530ae",
            "7a6afa11e7d94a31a8819c124aaabe5b",
            "075a2d0d738c41828c30dc67697ed96a",
            "f03fa20a07554d8db6d72e99ccf36597",
            "3cfa04c4d6724bfb81edb85adbb9d1d5",
            "ca66aa56f79d4eb9bcf060a52b3ec974"
          ]
        },
        "id": "OPmuMx05CdC8",
        "outputId": "2d6ee36b-62ac-4e91-a5ce-643d3e49c4bf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f9a449224ca4c2488e407d8a46e4f27",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/112823 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Loss: 7.6211\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aabeea0515f1436bb25c663560e7c6e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/112823 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/5], Loss: 6.7158\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f210aa1dc6d640359cfd689c326a9627",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/112823 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/5], Loss: 6.0447\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f66748d7eee4613b6a847b42ca21456",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/112823 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Loss: 5.5193\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1be81ff7d3b9443e9d0b688f1cb3e21a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/112823 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Loss: 5.0931\n"
          ]
        }
      ],
      "source": [
        "# Training loop with batching\n",
        "all_losses = []\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    batches = create_batches(training_pairs, batch_size)\n",
        "\n",
        "    for batch in tqdm(batches):\n",
        "        target_batch = []\n",
        "        context_batch = []\n",
        "        negative_samples_batch = []\n",
        "\n",
        "        for target_word_idx, context_word_idx in batch:\n",
        "            target_batch.append(target_word_idx)\n",
        "            context_batch.append(context_word_idx)\n",
        "\n",
        "            # Sample negative words for the batch\n",
        "            negative_samples = sample_negative_words(1, num_negative_samples, vocab_size, exclude={target_word_idx, context_word_idx})\n",
        "            negative_samples_batch.append(negative_samples)\n",
        "\n",
        "        target_batch = torch.tensor(target_batch, dtype=torch.long).to(device)\n",
        "        context_batch = torch.tensor(context_batch, dtype=torch.long).to(device)\n",
        "        negative_samples_batch = torch.stack(negative_samples_batch).squeeze(1)  # Stack the negative samples\n",
        "\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "\n",
        "        # Forward pass\n",
        "        positive_score, negative_scores = model(target_batch, context_batch, negative_samples_batch)\n",
        "\n",
        "        # Get the actual batch size\n",
        "        actual_batch_size = target_batch.shape[0]\n",
        "\n",
        "        # Loss for positive score (should be 1)\n",
        "        positive_labels = torch.ones(actual_batch_size).to(device)  # Positive sample labels with actual batch size\n",
        "        positive_loss = loss_fn(positive_score, positive_labels)\n",
        "\n",
        "        # Loss for negative scores (should be 0)\n",
        "        negative_labels = torch.zeros(actual_batch_size, num_negative_samples).to(device)  # Negative sample labels with actual batch size\n",
        "        negative_loss = loss_fn(negative_scores, negative_labels)\n",
        "\n",
        "        # Combine positive and negative losses\n",
        "        loss = positive_loss + negative_loss\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    average_loss = total_loss / len(batches)\n",
        "    all_losses.append(average_loss)\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {average_loss:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 5**: Plot Epochs vs. Training Error"
      ],
      "metadata": {
        "id": "iklRv1fJLG88"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "QD604f0xC8aA",
        "outputId": "5b664168-5ae1-4df4-da5c-583a7a21d4bd"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotting Epochs vs. Training Error\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, num_epochs + 1), all_losses, marker='o')\n",
        "plt.title('Epochs vs. Training Error (Negative Sampling with Batching)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Training Error (Loss)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Saving the trained model and word embeddings for future use."
      ],
      "metadata": {
        "id": "NQURYAVu4qhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'SkipGram_Neg_Samp_A4.pth')"
      ],
      "metadata": {
        "id": "QJ5bURrS4Yzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save word embeddings\n",
        "word_embeddings = model.in_embedding.weight.data.cpu().numpy()  # Move to CPU before saving\n",
        "\n",
        "# Create a DataFrame for word embeddings\n",
        "embeddings_df = pd.DataFrame(word_embeddings, index=vocabulary)\n",
        "embeddings_df.to_csv('word_embeddings.csv')"
      ],
      "metadata": {
        "id": "_b28IQSo4e7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 7**: Test Analogies\n",
        "Provide at least one example to test word analogies. The chosen words should not include the following\n",
        "terms: ”man,” ”woman,” ”boy,” ”girl,” ”country,” ”city,” ”malware,” ”virus,” and their synonyms. Ensure\n",
        "that two of the selected words used in the analogy are related to COVID-19."
      ],
      "metadata": {
        "id": "scZt5QpkLeYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load word embeddings from CSV\n",
        "embeddings_df = pd.read_csv('word_embeddings.csv', index_col=0)\n",
        "embeddings = torch.tensor(embeddings_df.values).to(device)  # Convert to tensor and move to GPU if available\n",
        "\n",
        "# Create a mapping from index to word\n",
        "idx_to_word = embeddings_df.index.tolist()\n",
        "word_to_idx = {word: idx for idx, word in enumerate(idx_to_word)}"
      ],
      "metadata": {
        "id": "ZHu7ZT2vcH2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Forbidden words and their synonyms\n",
        "forbidden_words = {\"man\", \"woman\", \"boy\", \"girl\", \"country\", \"city\", \"malware\", \"virus\"}\n",
        "\n",
        "# This can be expanded with more synonyms as needed\n",
        "forbidden_synonyms = {\"male\", \"female\", \"child\", \"nation\", \"metropolis\", \"infection\"}\n",
        "\n",
        "# COVID-19 related words (you can expand this list as needed)\n",
        "covid_related_words = {\"pandemic\", \"sickness\", \"infection\", \"quarantine\", \"transmission\", \"symptom\", \"outbreak\", \"prevention\", \"isolation\", \"vaccination\"}\n",
        "\n",
        "# Load word embeddings from CSV\n",
        "embeddings_df = pd.read_csv('word_embeddings.csv', index_col=0)\n",
        "\n",
        "# Create a list of available words, excluding forbidden words and their synonyms\n",
        "words_list = [word for word in embeddings_df.index if word not in forbidden_words and word not in forbidden_synonyms]\n",
        "\n",
        "# Create a list of available COVID-19 related words\n",
        "available_covid_words = [word for word in words_list if word in covid_related_words]"
      ],
      "metadata": {
        "id": "VozVoZq3-K1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_custom_examples(num_examples=5):\n",
        "    \"\"\"\n",
        "    Create custom analogy examples.\n",
        "    \"\"\"\n",
        "    examples = []\n",
        "    for _ in range(num_examples):\n",
        "        # Select two COVID-19 related words\n",
        "        word_a, word_b = random.sample(available_covid_words, 2)\n",
        "\n",
        "        # Select a third word from the general vocabulary (not restricted to COVID-19)\n",
        "        remaining_words = [word for word in words_list if word not in available_covid_words]\n",
        "        word_c = random.choice(remaining_words)\n",
        "\n",
        "        examples.append((word_a, word_b, word_c))\n",
        "    return examples"
      ],
      "metadata": {
        "id": "74-3TIYw-O--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the custom examples list\n",
        "examples = create_custom_examples(num_examples=5)\n",
        "print(np.array(examples))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZo1L180tw4b",
        "outputId": "a6431983-9c29-4cf2-aabd-2dfa718ff1e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['sickness' 'isolation' 'incidence']\n",
            " ['prevention' 'isolation' 'prototype']\n",
            " ['quarantine' 'pandemic' 'shocks']\n",
            " ['vaccination' 'quarantine' 'grains']\n",
            " ['pandemic' 'symptom' 'optimize']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given three words `word_a`, `word_b`, and `word_c`, we aim to find a fourth word `word_d` that completes the analogy:\n",
        "\n",
        "`word_a` is to `word_b` as `word_c` is to `word_d`\n",
        "\n",
        "$ \\text{or, } e_a - e_b ≃ e_c - e_d$\n",
        "\n",
        "To find `word_d`, we compute an analogy vector $v_{analogy}$ based on the embeddings $e_a$, $e_b$ and $e_c$\n",
        "\n",
        "$$\n",
        "\\vec{v}_{\\text{analogy}} = \\vec{e}_b - \\vec{e}_a + \\vec{e}_c\n",
        "$$\n",
        "\n",
        "This vector is then compared to each word embedding $e_w$ in the vocabulary by calculating the similarity:\n",
        "\n",
        "$$\n",
        "\\text{similarity} = \\vec{v}_{\\text{analogy}} \\cdot \\vec{e}_w\n",
        "$$\n",
        "\n",
        "The word with the highest similarity score is selected as the answer to the analogy."
      ],
      "metadata": {
        "id": "JzOsXo8BT_qq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_analogy(word_a, word_b, word_c):\n",
        "    \"\"\"\n",
        "    Test the analogy between word_a, word_b, and word_c.\n",
        "    \"\"\"\n",
        "    # Get the indices of the words\n",
        "    idx_a = word_to_idx[word_a]\n",
        "    idx_b = word_to_idx[word_b]\n",
        "    idx_c = word_to_idx[word_c]\n",
        "\n",
        "    # Calculate the analogy vector\n",
        "    analogy_vector = embeddings[idx_b] - embeddings[idx_a] + embeddings[idx_c]\n",
        "\n",
        "    # Get the nearest word in the vocabulary\n",
        "    similarities = torch.matmul(embeddings, analogy_vector)  # Similarity scores\n",
        "    most_similar_word_idx = torch.argmax(similarities).item()\n",
        "\n",
        "    # Return the most similar word\n",
        "    return idx_to_word[most_similar_word_idx]"
      ],
      "metadata": {
        "id": "d_aKx5iE43Dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing each analogy example\n",
        "for word_a, word_b, word_c in examples:\n",
        "    result = test_analogy(word_a, word_b, word_c)\n",
        "    BLUE = '\\033[94m'\n",
        "    RESET = '\\033[0m'\n",
        "    # Modified print statement\n",
        "    print(f\"Analogy result for '{word_a}' is to '{word_b}' as '{BLUE}{result}{RESET}' is to '{word_c}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0MfDcWDt0TK",
        "outputId": "9e82b754-1937-4f61-b144-4cc5b4f8af37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analogy result for 'sickness' is to 'isolation' as '\u001b[94mvertebrate\u001b[0m' is to 'incidence'\n",
            "Analogy result for 'prevention' is to 'isolation' as '\u001b[94mprototype\u001b[0m' is to 'prototype'\n",
            "Analogy result for 'quarantine' is to 'pandemic' as '\u001b[94mshocks\u001b[0m' is to 'shocks'\n",
            "Analogy result for 'vaccination' is to 'quarantine' as '\u001b[94mgrains\u001b[0m' is to 'grains'\n",
            "Analogy result for 'pandemic' is to 'symptom' as '\u001b[94moptimize\u001b[0m' is to 'optimize'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment 05\n",
        "\n",
        "There are two matrices in this word2vec `SkipGramNegSamp` model\n",
        "* $W_{in}$ - connecting the input and hidden layer\n",
        "* $W_{out}$ - connecting the hidden and the output layer\n",
        "\n",
        "Usually $W_{in}$ is used for word embedding and $W_{out}$ is ignored. In this assignment, you will execute the following:"
      ],
      "metadata": {
        "id": "ih9AnY_U1uNj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 1**: Find similar words for a word of your choice using $W_{in}$"
      ],
      "metadata": {
        "id": "nk1OhlXk1rtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create idx_to_word by reversing the word_to_idx dictionary\n",
        "idx_to_word = {index: word for word, index in word_to_idx.items()}"
      ],
      "metadata": {
        "id": "XYgtChe6pTRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_embedding(word, embedding_matrix, word_to_idx):\n",
        "    \"\"\"\n",
        "    Get the embedding vector for a given word.\n",
        "    \"\"\"\n",
        "    word_idx = word_to_idx[word]\n",
        "    return embedding_matrix[word_idx]\n",
        "\n",
        "def find_similar_words(word, embedding_matrix, word_to_idx, idx_to_word, top_k=5):\n",
        "    \"\"\"\n",
        "    Find similar words to a given word based on cosine similarity.\n",
        "    \"\"\"\n",
        "    # Get the embedding for the given word\n",
        "    word_embedding = get_word_embedding(word, embedding_matrix, word_to_idx)\n",
        "    similarities = []\n",
        "\n",
        "    # Compute cosine similarity with all other words\n",
        "    for i, embedding in enumerate(embedding_matrix):\n",
        "        sim = torch.cosine_similarity(torch.tensor(word_embedding), torch.tensor(embedding), dim=0)\n",
        "        similarities.append((idx_to_word[i], sim.item()))\n",
        "\n",
        "    # Sort by similarity and return the top-k most similar words\n",
        "    similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
        "    return similarities[:top_k]"
      ],
      "metadata": {
        "id": "EEXx7a6PiQ4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Win matrix\n",
        "similar_words_win = find_similar_words(\"patients\", model.in_embedding.weight.detach().cpu().numpy(), word_to_idx, idx_to_word)"
      ],
      "metadata": {
        "id": "geaiWClj1hnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar_words_win"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25fKeB0FpY6b",
        "outputId": "f7a9fc1a-27f6-43cf-a09c-991a0b7770ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('patients', 1.0),\n",
              " ('infection', 0.7654737234115601),\n",
              " ('disease', 0.7362645864486694),\n",
              " ('study', 0.7117049694061279),\n",
              " ('data', 0.6768487691879272)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Similar words for 'patients' (W_input):\")\n",
        "print()\n",
        "for word, similarity in similar_words_win:\n",
        "    print(f'{word}: {similarity:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UieaZwF_N3E",
        "outputId": "8ab7fcc1-7fa5-4378-cfca-e0f62567d17f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similar words for 'patients' (W_input):\n",
            "\n",
            "patients: 1.0000\n",
            "infection: 0.7655\n",
            "disease: 0.7363\n",
            "study: 0.7117\n",
            "data: 0.6768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 2**: Find the similar words for the same word chosen in (1) using $W_{out}$"
      ],
      "metadata": {
        "id": "oyw67ERz14zV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Wout matrix\n",
        "similar_words_wout = find_similar_words(\"patients\", model.out_embedding.weight.detach().cpu().numpy(), word_to_idx, idx_to_word)"
      ],
      "metadata": {
        "id": "wAfPCnzfpgvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar_words_wout"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLl79yfzqAa6",
        "outputId": "0dafb549-568c-4ddf-a0db-01e053ad94ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('patients', 1.0000001192092896),\n",
              " ('pandemic', 0.45847299695014954),\n",
              " ('infection', 0.42095503211021423),\n",
              " ('study', 0.39711931347846985),\n",
              " ('may', 0.3768135607242584)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Similar words for 'patients' (W_output):\")\n",
        "print()\n",
        "for word, similarity in similar_words_wout:\n",
        "    print(f'{word}: {similarity:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UseH2XhG25eB",
        "outputId": "a8a4f438-b1c6-4299-d122-9211a2b61401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similar words for 'patients' (W_output):\n",
            "\n",
            "patients: 1.0000\n",
            "pandemic: 0.4585\n",
            "infection: 0.4210\n",
            "study: 0.3971\n",
            "may: 0.3768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 3** : Find the similar words for the same word chosen in (1) after combining $W_{in}$ and $W_{out}$ - either concatenate them to have a longer vector or average them out"
      ],
      "metadata": {
        "id": "xBboVK982C5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_embeddings(word, in_matrix, out_matrix, word_to_idx, method='concat'):\n",
        "    \"\"\"\n",
        "    Combine embeddings from in_matrix and out_matrix based on the specified method.\n",
        "    \"\"\"\n",
        "    # Assuming idx_to_word is a dictionary mapping index to word\n",
        "    word = idx_to_word.get(word)  # If word is an index, get the actual word\n",
        "\n",
        "    if word is not None and word in word_to_idx:\n",
        "        in_embedding = get_word_embedding(word, in_matrix, word_to_idx)\n",
        "        out_embedding = get_word_embedding(word, out_matrix, word_to_idx)\n",
        "\n",
        "        if method == 'concat':\n",
        "            combined_embedding = np.concatenate((in_embedding, out_embedding))\n",
        "        elif method == 'average':\n",
        "            combined_embedding = (in_embedding + out_embedding) / 2\n",
        "\n",
        "        return combined_embedding\n",
        "    else:\n",
        "        return np.zeros(in_matrix.shape[1] + out_matrix.shape[1] if method == 'concat' else in_matrix.shape[1])"
      ],
      "metadata": {
        "id": "rBrpBEgtqCKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Using `average` of $W_{in}$ and $W_{out}$ for `combined_embeddings`"
      ],
      "metadata": {
        "id": "g1VWLTLz9Xcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_embeddings = np.array([combine_embeddings(w, model.in_embedding.weight.detach().cpu().numpy(),\n",
        "                                        model.out_embedding.weight.detach().cpu().numpy(),\n",
        "                                        word_to_idx, method='average') for w in idx_to_word])"
      ],
      "metadata": {
        "id": "pctnBBrR9RF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar_words_combined = find_similar_words(\"patients\", combined_embeddings, word_to_idx, idx_to_word)"
      ],
      "metadata": {
        "id": "u9fe9ZnS9p2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar_words_combined"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYwt9Bg_qLrR",
        "outputId": "2bcdbb6a-b583-4ca0-df1e-151e159b5492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('patients', 0.9999998807907104),\n",
              " ('pandemic', 0.5272459387779236),\n",
              " ('infection', 0.52550208568573),\n",
              " ('study', 0.5064181685447693),\n",
              " ('may', 0.4640401303768158)]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Similar words for 'patients' (W_combined):\")\n",
        "print()\n",
        "for word, similarity in similar_words_combined:\n",
        "    print(f'{word}: {similarity:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrTFBH1V3T0Z",
        "outputId": "20905c70-9950-4293-8f38-80788532024e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similar words for 'patients' (W_combined):\n",
            "\n",
            "patients: 1.0000\n",
            "pandemic: 0.5272\n",
            "infection: 0.5255\n",
            "study: 0.5064\n",
            "may: 0.4640\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 4**: Compare the results of (1), (2) and (3) and write a brief description of the outcome"
      ],
      "metadata": {
        "id": "0PZOwdkB2P_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comparison of Results\n",
        "1. Similar Words from Input Embeddings ($W_{in}$):\n",
        "\n",
        "  * The top similar words for the query `patients` were `infection`, `disease`, `study`, and `data`, with a maximum similarity score of 1.0000 for the word itself.\n",
        "  * This outcome indicates that $W_{in}$ effectively captures relationships related to medical terms and research, reflecting its focus on context within input sentences.\n",
        "\n",
        "2. Similar Words from Output Embeddings ($W_{out}$):\n",
        "\n",
        "  * For $W_{out}$, the similar words were `pandemic`,`infection`, `study`, and `may`, with a maximum similarity score of 1.0000 for the word itself.\n",
        "  * The presence of `pandemic` highlights a broader contextual understanding, suggesting that the output embeddings capture not only the immediate context but also extend to related concepts, possibly influenced by the surrounding training data.\n",
        "\n",
        "3. Similar Words from Combined Embeddings ($W_{comb}$):\n",
        "\n",
        "  * The combined embeddings yielded similar words including `pandemic`, `infection`, `study`, and `may`, with the highest similarity score at 1.0000 for the word itself.\n",
        "  * Although the top similar words are the same as those from\n",
        "$W_{out}$, the similarity scores differ slightly, indicating that\n",
        "$W_{comb}$, $W_{in}$ and $W_{out}$, albeit leaning more towards the characteristics of\n",
        "$W_{out}$."
      ],
      "metadata": {
        "id": "MDmWUyikz2Bw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comments**:\n",
        "\n",
        "* The results illustrate that while both $W_{out}$ and $W_{comb}$  provide $W_{in}$,  focuses more on specific medical contexts.\n",
        "* This suggests that the input embeddings capture detailed semantic nuances, whereas the output embeddings, particularly in their combined form, tend to generalize concepts more broadly.\n",
        "* The similarity scores highlight the unique contributions of each embedding type, emphasizing the importance of considering different embedding strategies in natural language processing tasks.\n",
        "* Future training with additional epochs may further enhance the distinctiveness and effectiveness of these embeddings."
      ],
      "metadata": {
        "id": "mrBxpzIQ05rf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 5**: A slide related to the complexities of skipgram and CBOW model was shown in the class. Check if they are correct. If not, what are the correct entries?"
      ],
      "metadata": {
        "id": "s9UERj5Z2VEc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Model: Skip-gram with Negative Sampling**  \n",
        "\n",
        "**Skip-gram Model**:\n",
        "\n",
        "* The **Skip-gram** model aims to predict context words given a target word.  \n",
        "* For each target word, several context words (within a window) are used, and negative sampling is employed to predict unrelated words (negative samples).\n",
        "\n",
        "**Negative Sampling**:\n",
        "\n",
        "* The goal of **negative sampling** is to update only a few of the output weights rather than the entire output layer.\n",
        "* Instead of updating the entire vocabulary, it updates a small subset of words.  \n",
        "\n",
        "**Complexity of the Skip-gram Model with Negative Sampling**:\n",
        "\n",
        "From the slide, the complexity is:\n",
        "`O(T · N · C · k)`\n",
        "\n",
        "Where:\n",
        "\n",
        "- **T**: Total number of words in the corpus.  \n",
        "- **N**: Embedding size (here, `embedding_dim = 128`).  \n",
        "- **C**: Context window size (here, `window_size = 2`).  \n",
        "- **k**: Number of negative samples (here, `num_negative_samples = 5`).  "
      ],
      "metadata": {
        "id": "MXxJC1ETVBSk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above model follows this complexity because:\n",
        "\n",
        "- The forward pass involves dot products between the target word and context word embeddings (`target_embedding * context_embedding`) for positive pairs.  \n",
        "- Similarly, for negative sampling, I have performed dot products between the target word embedding and negative word embeddings.  \n",
        "- For each word, I am calculating both positive and negative losses, so the number of operations per word is proportional to **C** (number of context words) and **k** (negative samples).\n",
        "\n",
        "Thus, **this model’s complexity is indeed `O(T · N · C · k)`**."
      ],
      "metadata": {
        "id": "9erEoXULVU6F"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}