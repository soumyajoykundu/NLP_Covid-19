{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Natural Language Processing\n",
        "* Name: Soumyajoy Kundu\n",
        "* Roll Number: MDS202349"
      ],
      "metadata": {
        "id": "5eZRH1XXuWLE"
      },
      "id": "5eZRH1XXuWLE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Assignment 06, 07 and 08\n",
        "#### Abstract Generation from Covid-19 articles\n",
        "\n",
        "* Use this partial data set (sourced from Kaggle) which contains research articles related to COVID-19. (same used in Assignment 01)\n",
        "* This corpus has around 56000+ files.\n",
        "* All the instructions are followed that were mentioned in Assignment 01 - 05.\n",
        "* Develop a contextualized language model employing a two-layer vanilla recurrent neural network\n",
        "(RNN), long short-term memory (LSTM), or gated recurrent unit (GRU).\n",
        "* The model should be\n",
        "implemented using any machine learning library of your choice, such as PyTorch, TensorFlow, or similar.\n",
        "\n",
        "**Note**:\n",
        "All fine prints from the earlier assignments apply here with respect to submission guidelines."
      ],
      "metadata": {
        "id": "S_phiW4ou2TD"
      },
      "id": "S_phiW4ou2TD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Assignment 06**\n",
        "Implement a small language model with a minimum of two hidden states consisting of a  forward and backward pass.\n",
        "* `Task 1`- Description of the architecture\n",
        "* `Task 2`- Python implementation\n"
      ],
      "metadata": {
        "id": "BlAV3bt6r-D1"
      },
      "id": "BlAV3bt6r-D1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Assignment 07**\n",
        "**Input**: Abstracts from the COVID-19 corpus. Experiment with a hundred abstracts before extending to\n",
        "the entire corpus. Plot the error graph during the training process.  \n",
        "* `Task 1`- Creation of the corpus\n",
        "* `Task 2`- Training and plotting"
      ],
      "metadata": {
        "id": "-tICVm15NgBT"
      },
      "id": "-tICVm15NgBT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "### **Assignment 08**\n",
        "Utilize your trained model to generate abstracts. Concisely describe your approach and present the key\n",
        "results obtained.\n",
        "**Note on Potential Reasons for Sub-Optimal Results.**\n",
        "Compose a note comprising three distinct points that may contribute to sub-optimal results. Provide\n",
        "specific suggestions on how these factors could be mitigated or improved.\n",
        "* `Task 1`- Abstract generation\n",
        "* `Task 2`- Discussion of the results\n",
        "\n"
      ],
      "metadata": {
        "id": "pYicBOytNjRe"
      },
      "id": "pYicBOytNjRe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries"
      ],
      "metadata": {
        "id": "qPKcsos_Nl-q"
      },
      "id": "qPKcsos_Nl-q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1P30n6nTU7Lv"
      },
      "outputs": [],
      "source": [
        "import os  # For interacting with the operating system\n",
        "import re  # For regular expressions\n",
        "import time  # For measuring time\n",
        "import json  # For handling JSON files\n",
        "import zipfile  # For handling zip files\n",
        "import string  # For string manipulation\n",
        "import csv  # For handling CSV files\n",
        "import pickle  # For serializing and deserializing Python objects\n",
        "from collections import Counter  # For counting elements\n",
        "import numpy as np  # For numerical operations\n",
        "import matplotlib.pyplot as plt  # For plotting\n",
        "import math  # For mathematical functions\n",
        "from multiprocessing import Pool, Manager  # For parallel processing"
      ],
      "id": "1P30n6nTU7Lv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OrXaFD-zz4x"
      },
      "source": [
        "  * Used TPU v2-8\n",
        "  * Number of cores = 96"
      ],
      "id": "2OrXaFD-zz4x"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv2omN8m9-Jw",
        "outputId": "53fb8fce-b811-4fb9-83be-e090db868dfd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "tpu_num_cores = os.cpu_count()\n",
        "tpu_num_cores"
      ],
      "id": "pv2omN8m9-Jw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzx7AOb3vs9o",
        "outputId": "1fbcdd0c-cb32-4780-ed12-1eed14151787"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted to /content/pdf_json\n",
            "Time taken to unzip: 36.20004320144653 seconds\n"
          ]
        }
      ],
      "source": [
        "# Path to the zip file\n",
        "zip_file_path = '/content/pdf_json.zip'\n",
        "\n",
        "# Path where the file is extracted\n",
        "extract_dir = '/content/pdf_json'\n",
        "\n",
        "start = time.time()\n",
        "# Creating the directory if it doesn't exist\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Files extracted to {extract_dir}\")\n",
        "print(f\"Time taken to unzip: {end-start} seconds\")"
      ],
      "id": "hzx7AOb3vs9o"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvV4Eo7JR9BI",
        "outputId": "35b63108-f4fb-4a92-cdad-a2292d6a300d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total JSON files extracted: 56528\n",
            "First 10 files: ['481f6c73c028491b1f17adb579cd764646d70c51.json', '6f2a507b31c76fb14fcdbe335f7ba2145c5fe162.json', '52d994a20f5f2747dedcd2c25763b3341f663326.json', '40d1dd0f992de32e06c688811ecc8445826cee20.json', '6502ec8499162886322b81f183705d278044d7d5.json', '5476d0364141435f4731a84c473d77cdf3812e93.json', '149b84f96e7d375225d860813eaa233c577a8aa1.json', '2764ffe80de591762fa622ca85c04d037f5af583.json', '529076e3b1ecf8b2e7ef44c9ccaf34812277ff6d.json', '286bea94529dca847214023bb3eabc8b2bc59760.json']\n"
          ]
        }
      ],
      "source": [
        "# List a few files to confirm extraction\n",
        "json_files = [f for f in os.listdir('/content/pdf_json/pdf_json') if f.endswith('.json')]\n",
        "\n",
        "print(f\"Total JSON files extracted: {len(json_files)}\")\n",
        "print(\"First 10 files:\", json_files[:10])"
      ],
      "id": "TvV4Eo7JR9BI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **A7-T1**"
      ],
      "metadata": {
        "id": "6TPB1GA7u7ft"
      },
      "id": "6TPB1GA7u7ft"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Use the COVID-19 corpus\n",
        "* Extract all the abstracts from the COVID-19 text files and use them as the corpus."
      ],
      "metadata": {
        "id": "Uxyo4fAFtfem"
      },
      "id": "Uxyo4fAFtfem"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--l8ITGVvNeO"
      },
      "source": [
        "\n",
        "* Extract the text content from the JSON-encoded data set and create a\n",
        "text corpus.\n",
        "* You may use any JSON library to extract the text"
      ],
      "id": "--l8ITGVvNeO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7sV_JUuSXQT"
      },
      "outputs": [],
      "source": [
        "def json2text(filename):\n",
        "    '''\n",
        "    Converts a JSON file to text.\n",
        "    '''\n",
        "    # Construct the full file path\n",
        "    filepath = os.path.join('/content/pdf_json/pdf_json', filename)  # Add the directory path\n",
        "\n",
        "    with open(filepath, encoding='latin-1') as file: # Use filepath instead of filename\n",
        "        if filename.endswith('.json'):\n",
        "            paper_content = json.load(file)\n",
        "    abstract = \"\"\n",
        "    title = \"\"\n",
        "\n",
        "    # get the paper_id\n",
        "    paper_id = paper_content['paper_id']\n",
        "\n",
        "    # get the title\n",
        "    if 'title' in paper_content:\n",
        "      title = paper_content['title']\n",
        "\n",
        "    # get the abstract\n",
        "    if 'abstract' in paper_content:\n",
        "      for abs in paper_content['abstract']:\n",
        "          abstract = abstract + abs['text']\n",
        "\n",
        "    # case-folding (all converted to lower case)\n",
        "    return abstract.lower()"
      ],
      "id": "v7sV_JUuSXQT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hd_6F269aXze"
      },
      "outputs": [],
      "source": [
        "def save_text_to_file(text, filename, output_dir):\n",
        "    \"\"\"\n",
        "    Saves the given text to a file in the specified output directory.\n",
        "    \"\"\"\n",
        "    # Ensure the output directory exists\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Define the path to save the text file\n",
        "    text_filename = os.path.join(output_dir, f\"{filename}.txt\")\n",
        "\n",
        "    # Write the text to the file\n",
        "    with open(text_filename, 'w', encoding='utf-8') as file:\n",
        "        file.write(text)"
      ],
      "id": "hd_6F269aXze"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqnjMtQET35J"
      },
      "outputs": [],
      "source": [
        "def process_json_file(json_file, output_dir):\n",
        "    \"\"\"\n",
        "    Processes a single JSON file: extracts text and saves it to a file.\n",
        "    \"\"\"\n",
        "    text = json2text(json_file)\n",
        "\n",
        "    # Extract the base filename (without extension) to use as the text file name\n",
        "    base_filename = os.path.splitext(os.path.basename(json_file))[0]\n",
        "\n",
        "    # Save the extracted text to a file\n",
        "    save_text_to_file(text, base_filename, output_dir)"
      ],
      "id": "mqnjMtQET35J"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dyb_dEQ5aiW_"
      },
      "outputs": [],
      "source": [
        "def extract_texts(json_files, output_dir):\n",
        "    \"\"\"\n",
        "    Extracts text content from a list of JSON files in parallel and saves each text\n",
        "    into a separate file within the specified output directory.\n",
        "    \"\"\"\n",
        "    cpu_count = os.cpu_count()\n",
        "    pool = Pool(processes=cpu_count)\n",
        "\n",
        "    # Using starmap to pass both json_file and output_dir to process_json_file\n",
        "    pool.starmap(process_json_file, [(json_file, output_dir) for json_file in json_files])\n",
        "\n",
        "    pool.close()\n",
        "    pool.join()"
      ],
      "id": "Dyb_dEQ5aiW_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t541FljHd1W1",
        "outputId": "455cc7b0-149b-4520-a417-b66397aaf4b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All json files are converted to text files containing abstracts...\n",
            "Time taken to extract texts: 5.538058280944824 seconds\n"
          ]
        }
      ],
      "source": [
        "# Path to create a folder where the json to text files will be kept.\n",
        "output_dir = '/content/abstracts'\n",
        "\n",
        "start = time.time()\n",
        "extract_texts(json_files, output_dir)\n",
        "end = time.time()\n",
        "\n",
        "print(\"All json files are converted to text files containing abstracts...\")\n",
        "print(f\"Time taken to extract texts: {end-start} seconds\")"
      ],
      "id": "t541FljHd1W1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVCaTskavYzi"
      },
      "source": [
        "#### Text Preprocessing\n",
        "* Develop your pre-processing steps and order of steps.\n",
        "* Some examples: case-folding, removal of numbers, etc.\n",
        "* As the heart of this task is Generating the text, so the `stopwords` are not removed from the preprocessed text."
      ],
      "id": "LVCaTskavYzi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZEVOedSKfe6"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries for NLP Tasks\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk"
      ],
      "id": "mZEVOedSKfe6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyaAl1fZ0Ksq",
        "outputId": "c95320fb-74e6-4a43-aa5d-234604a97a3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Downloading pyspellchecker-0.8.1-py3-none-any.whl (6.8 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/6.8 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/6.8 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/6.8 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.8.1\n"
          ]
        }
      ],
      "source": [
        "pip install pyspellchecker"
      ],
      "id": "LyaAl1fZ0Ksq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sZ6YMNK0TKC"
      },
      "outputs": [],
      "source": [
        "from spellchecker import SpellChecker"
      ],
      "id": "_sZ6YMNK0TKC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1zpLnJKVO1J"
      },
      "outputs": [],
      "source": [
        "def preprocess_file(filepath, output_dir):\n",
        "    \"\"\"\n",
        "    Preprocesses the text content of a single file by performing case-folding, removing numbers, and punctuation.\n",
        "    Saves the preprocessed text to a new file in the output directory.\n",
        "    Includes additional preprocessing steps based on user specifications.\n",
        "    \"\"\"\n",
        "    with open(filepath, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "\n",
        "    # 1. Remove non-ascii characters\n",
        "    text = text.encode('ascii', errors='ignore').decode()\n",
        "\n",
        "    # 2. Remove [numbers] in this format\n",
        "    text = re.sub(r'\\[\\d+\\]', '', text)\n",
        "\n",
        "    # 3. Remove punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # 3. Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # 4. Remove non-alphanumeric characters\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "\n",
        "    # 5. Case folding (convert to lowercase)\n",
        "    text = text.lower()\n",
        "\n",
        "    # 6. Remove single-letter words (e.g., 'a', 'b')\n",
        "    text = re.sub(r'\\b[a-z]\\b', '', text)\n",
        "\n",
        "    # 7. Remove any email id, URL, or number with more than 9 digits\n",
        "    text = re.sub(r'\\S+@\\S+', '', text)  # Remove email addresses\n",
        "    text = re.sub(r'http\\S+|www\\S+', '', text)  # Remove URLs\n",
        "    text = re.sub(r'\\b\\d{10,}\\b', '', text)  # Remove numbers greater than 9 digits\n",
        "\n",
        "    # 8. Convert \"$\" to \"dollars\"\n",
        "    text = text.replace('$', 'dollars')\n",
        "\n",
        "    # 9. Remove words longer than 20 characters\n",
        "    text = ' '.join([word for word in text.split() if len(word) <= 20])\n",
        "\n",
        "    # 10. Spell check and remove words with incorrect spelling\n",
        "    spell = SpellChecker()\n",
        "    words = text.split()\n",
        "    misspelled = spell.unknown(words)\n",
        "    text = ' '.join([word for word in words if word not in misspelled])\n",
        "\n",
        "    # 11. Remove extra spaces created by the removal of unwanted characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # Save the preprocessed text to the output directory\n",
        "    filename = os.path.basename(filepath)\n",
        "    output_path = os.path.join(output_dir, filename)\n",
        "    with open(output_path, 'w', encoding='utf-8') as output_file:\n",
        "        output_file.write(text)"
      ],
      "id": "_1zpLnJKVO1J"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veLDw2nAcVQW"
      },
      "outputs": [],
      "source": [
        "def preprocess_corpus_multiprocessing(input_dir, output_dir):\n",
        "    \"\"\"\n",
        "    Preprocesses all text files in the specified directory using multiprocessing and saves them to the output directory.\n",
        "    \"\"\"\n",
        "    # Create the output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Get the list of all text files in the input directory\n",
        "    text_files = [os.path.join(input_dir, filename) for filename in os.listdir(input_dir) if filename.endswith('.txt')]\n",
        "\n",
        "    # Use multiprocessing to preprocess the files\n",
        "    cpu_count = os.cpu_count()\n",
        "    with Pool(processes=cpu_count) as pool:\n",
        "        pool.starmap(preprocess_file, [(filepath, output_dir) for filepath in text_files])"
      ],
      "id": "veLDw2nAcVQW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prbZXFtm1DdY",
        "outputId": "a818ac7c-c956-464c-db49-2a0981e84f65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Preprocessing Done!\n",
            "Time taken to preprocess: 171.23124599456787 seconds\n"
          ]
        }
      ],
      "source": [
        "# Path for converted text files\n",
        "input_directory = '/content/abstracts'\n",
        "\n",
        "# Path to create a folder for the Preprocessed text files\n",
        "output_directory = '/content/abstracts_all'\n",
        "\n",
        "start = time.time()\n",
        "preprocess_corpus_multiprocessing(input_directory, output_directory)\n",
        "end = time.time()\n",
        "\n",
        "print(\"Text Preprocessing Done!\")\n",
        "print(f\"Time taken to preprocess: {end-start} seconds\")"
      ],
      "id": "prbZXFtm1DdY"
    },
    {
      "cell_type": "code",
      "source": [
        "combined_text = \"\"\n",
        "for file in os.listdir('/content/abstracts_all_prep'):\n",
        "    if file.endswith('.txt'):\n",
        "        with open(os.path.join('/content/abstracts_all_prep', file), 'r') as f:\n",
        "            with open('abstracts_all.txt', 'a') as combined_file:\n",
        "                combined_file.write(f.read() + '\\n')"
      ],
      "metadata": {
        "id": "vk6S32enA4n_"
      },
      "execution_count": null,
      "outputs": [],
      "id": "vk6S32enA4n_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "015f575b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-05T19:29:12.185234Z",
          "iopub.status.busy": "2023-04-05T19:29:12.184853Z",
          "iopub.status.idle": "2023-04-05T19:29:12.197393Z",
          "shell.execute_reply": "2023-04-05T19:29:12.196186Z"
        },
        "papermill": {
          "duration": 0.02172,
          "end_time": "2023-04-05T19:29:12.199927",
          "exception": false,
          "start_time": "2023-04-05T19:29:12.178207",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "015f575b",
        "outputId": "2fe4cd26-b356-4c03-ad3c-9beb27690a1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7e7da6dd3f70>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set seed for reproducibility\n",
        "torch.manual_seed(2024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-05T19:29:12.212122Z",
          "iopub.status.busy": "2023-04-05T19:29:12.211192Z",
          "iopub.status.idle": "2023-04-05T19:29:12.278823Z",
          "shell.execute_reply": "2023-04-05T19:29:12.277843Z"
        },
        "papermill": {
          "duration": 0.076212,
          "end_time": "2023-04-05T19:29:12.281257",
          "exception": false,
          "start_time": "2023-04-05T19:29:12.205045",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b79b78f-8968-4429-8751-e3f3ffbfa239",
        "id": "4H5GRJT_T2jG"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# setting device to gpu if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "id": "4H5GRJT_T2jG"
    },
    {
      "cell_type": "markdown",
      "id": "3d27261a",
      "metadata": {
        "id": "3d27261a"
      },
      "source": [
        "#### Creating a Text Dataset\n",
        "\n",
        "* Custom dataset class `TextDataset` which outputs sequences of a given length along with the next word to be predicted.\n",
        "* Sequences are generated by taking a window length of the sequence and that is then moved on the dataset to obtain the samples.\n",
        "* If an abstract is smaller than the sequence length, it is dropped. (not many are dropped when taking sequence length to be 40 or 50)\n",
        "* A window skip parameter is given which skips that many number of words to get the next sequence.\n",
        "\n",
        "This helps reduce the training data while not losing too much information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb8b7de6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-05T19:29:12.292679Z",
          "iopub.status.busy": "2023-04-05T19:29:12.291706Z",
          "iopub.status.idle": "2023-04-05T19:29:12.306503Z",
          "shell.execute_reply": "2023-04-05T19:29:12.305481Z"
        },
        "papermill": {
          "duration": 0.02287,
          "end_time": "2023-04-05T19:29:12.308858",
          "exception": false,
          "start_time": "2023-04-05T19:29:12.285988",
          "status": "completed"
        },
        "tags": [],
        "id": "bb8b7de6"
      },
      "outputs": [],
      "source": [
        "class TextDataset(Dataset):\n",
        "    '''\n",
        "    Custom Dataset class which outputs sequences of a given length along with the next word to be predicted.\n",
        "    '''\n",
        "    def __init__(self, file, seq_length, window_skip):\n",
        "        self.seq_len = seq_length\n",
        "        self.window_skip = window_skip\n",
        "        self.lines = self.load_lines(file)\n",
        "        self.vocab = self.uniq_words()\n",
        "\n",
        "        # Make dictionaries for word to idx and inverse\n",
        "        self.idx_to_word = {index: word for index, word in enumerate(self.vocab)}\n",
        "        self.word_to_idx = {word: index for index, word in enumerate(self.vocab)}\n",
        "\n",
        "        # Converts all the lines with words to lines with indices of the word\n",
        "        self.lines_indices = [[self.word_to_idx[x] for x in line] for line in filter(lambda x: len(x)>self.seq_len,self.lines)]\n",
        "\n",
        "        self.converted_idx = self.index_convert()\n",
        "        self.total_seq = len(self.converted_idx)\n",
        "\n",
        "    def load_lines(self, file):\n",
        "        '''\n",
        "        Loads the given file and adds <start> and <end> markers to the them.\n",
        "        '''\n",
        "        with open(file) as f:\n",
        "            lines = f.readlines()\n",
        "        lines = [[\"<s>\"]+line.split(\" \")+[\"</s>\"] for line in lines]\n",
        "        return lines\n",
        "\n",
        "    def uniq_words(self):\n",
        "        '''\n",
        "        Extracts the unique words from the corpus and sorts them to build a vocabulary and give them indices.\n",
        "        '''\n",
        "        counts = Counter()\n",
        "        list(map(lambda x: counts.update(x), self.lines))\n",
        "        return sorted(counts, key=counts.get, reverse=True)\n",
        "\n",
        "    def index_convert(self):\n",
        "        '''\n",
        "        Creates an auxillary array so that when asked for the i-th sequence, it returns the index in terms of the\n",
        "        index in the list of the abstracts. This way we don't have to coonstruct all the sequences and helps with\n",
        "        reducing the space usage.\n",
        "        '''\n",
        "        ls = []\n",
        "        for a,b in enumerate(self.lines_indices):\n",
        "            p = len(b)-self.seq_len-1\n",
        "            seqs = list(range(0, p+1, self.window_skip))\n",
        "            if p%self.window_skip != 0:\n",
        "                seqs.append(p)\n",
        "            ls.extend(zip([a]*len(seqs), seqs))\n",
        "        return ls\n",
        "\n",
        "    def vocab_size(self):\n",
        "        '''\n",
        "        Returns the size of the vocabulary\n",
        "        '''\n",
        "        return len(self.vocab)\n",
        "\n",
        "    def __len__(self):\n",
        "        '''\n",
        "        Required functions for dataset class\n",
        "        '''\n",
        "        return len(self.converted_idx)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        '''\n",
        "        Returns the i-th index in terms of an input and expected output, both as torch tensors\n",
        "        '''\n",
        "        return (torch.tensor(self.lines_indices[self.converted_idx[index][0]][self.converted_idx[index][1]:(self.converted_idx[index][1]+self.seq_len)]),\n",
        "                torch.tensor(self.lines_indices[self.converted_idx[index][0]][(self.converted_idx[index][1]+1):(self.converted_idx[index][1]+self.seq_len+1)]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "205cb47e",
      "metadata": {
        "id": "205cb47e"
      },
      "source": [
        "* The dataset will be constructed with 40 length sequences and sliding the window over 4 words everytime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b346ba03",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-05T19:29:12.319758Z",
          "iopub.status.busy": "2023-04-05T19:29:12.319449Z",
          "iopub.status.idle": "2023-04-05T19:29:16.984168Z",
          "shell.execute_reply": "2023-04-05T19:29:16.983110Z"
        },
        "papermill": {
          "duration": 4.673145,
          "end_time": "2023-04-05T19:29:16.986758",
          "exception": false,
          "start_time": "2023-04-05T19:29:12.313613",
          "status": "completed"
        },
        "tags": [],
        "id": "b346ba03"
      },
      "outputs": [],
      "source": [
        "text_dat = TextDataset(\"/content/abstracts_all_prep.txt\", 40, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eeca2507",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-05T19:29:16.997180Z",
          "iopub.status.busy": "2023-04-05T19:29:16.996862Z",
          "iopub.status.idle": "2023-04-05T19:29:17.019717Z",
          "shell.execute_reply": "2023-04-05T19:29:17.018662Z"
        },
        "papermill": {
          "duration": 0.030556,
          "end_time": "2023-04-05T19:29:17.021938",
          "exception": false,
          "start_time": "2023-04-05T19:29:16.991382",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "eeca2507",
        "outputId": "2291a4f6-c6ae-4073-d238-926525a5a7f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'and when to release statement of emergency was also assessed using the model furthermore results suggest that the rapid isolation of infectious cases has large potential to effectively mitigate the spread of infection and restores social and economic activities novel'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# An example of the 1341th sequence in the dataset\n",
        "\" \".join([text_dat.idx_to_word[x] for x in torch.Tensor.tolist(text_dat[1341][1])])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7378d169",
      "metadata": {
        "id": "7378d169"
      },
      "source": [
        "### **A6-T1**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LSTM: Model Architecture\n",
        "\n",
        "#### **Initialization Method**\n",
        "\n",
        "**Method:** `__init__(self, dataset)`\n",
        "\n",
        "**Input:**  \n",
        "- `dataset`: Custom dataset object containing vocabulary size and sequence length.\n",
        "\n",
        "**Process:**  \n",
        "- **Embedding Layer:** Initializes word embeddings with a size of `(vocab_size, embedding_dims = 256)`.  \n",
        "- **LSTM Layer:**  \n",
        "  - Two-layer LSTM with 128 hidden units (`lstm_size = 128`).  \n",
        "  - Unidirectional processing (`bidirectional = False`).  \n",
        "- **Decoder Layer:** Fully connected layer (`fc`) maps LSTM outputs to vocabulary size (`vocab_size`).  \n",
        "\n",
        "**Components:**  \n",
        "- `self.embedding`: Maps input tokens to dense vectors.  \n",
        "- `self.LSTM`: Processes the embedded input sequences.  \n",
        "- `self.fc`: Projects LSTM output to vocabulary space.  \n",
        "\n",
        "---\n",
        "\n",
        "#### **Forward Method**\n",
        "\n",
        "**Method:** `forward(self, x, prev_state)`\n",
        "\n",
        "**Input:**  \n",
        "- `x`: Tensor of input word indices (shape: `(batch_size, seq_len)`).  \n",
        "- `prev_state`: Tuple containing the initial hidden and cell states of the LSTM (shape: `(num_layers, batch_size, lstm_size)`).\n",
        "\n",
        "**Process:**  \n",
        "- **Embedding:** Converts input word indices to dense embeddings.  \n",
        "- **LSTM Processing:** Passes embeddings through the LSTM layers.  \n",
        "- **Decoding:** Maps LSTM outputs to vocabulary logits through a fully connected layer.  \n",
        "\n",
        "**Output:**  \n",
        "- `out`: Tensor of vocabulary logits (shape: `(batch_size, seq_len, vocab_size)`).  \n",
        "- `new_state`: Updated hidden and cell states of the LSTM.\n",
        "\n",
        "---\n",
        "\n",
        "#### **State Initialization Method**\n",
        "\n",
        "**Method:** `init_state(self, batch_size)`\n",
        "\n",
        "**Input:**  \n",
        "- `batch_size`: Number of sequences processed in a batch.\n",
        "\n",
        "**Process:**  \n",
        "- Initializes hidden (`h_0`) and cell (`c_0`) states to zero tensors on the appropriate device (CPU or GPU).\n",
        "\n",
        "**Output:**  \n",
        "- Tuple containing initial hidden and cell states, both of shape `(num_layers, batch_size, lstm_size)`.\n",
        "\n"
      ],
      "metadata": {
        "id": "NzkJVIsG5kcf"
      },
      "id": "NzkJVIsG5kcf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **A6-T2**"
      ],
      "metadata": {
        "id": "J1Tw0LorvRos"
      },
      "id": "J1Tw0LorvRos"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Python Implementation"
      ],
      "metadata": {
        "id": "-R9z1JMnHKGX"
      },
      "id": "-R9z1JMnHKGX"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, dataset):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.embedding_dims = 256\n",
        "        self.lstm_size = 128\n",
        "        self.num_layers = 2\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.seq_len = dataset.seq_len\n",
        "\n",
        "        self.vocab_size = dataset.vocab_size()\n",
        "\n",
        "        # Embedding Layer\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=self.vocab_size,\n",
        "            embedding_dim=self.embedding_dims\n",
        "        )\n",
        "\n",
        "        # LSTM Layer (Unidirectional)\n",
        "        self.LSTM = nn.LSTM(\n",
        "            input_size=self.embedding_dims,\n",
        "            hidden_size=self.lstm_size,\n",
        "            num_layers=self.num_layers,\n",
        "            bidirectional=False\n",
        "        )\n",
        "\n",
        "        # Decoder Layer (Fully Connected)\n",
        "        self.fc = nn.Linear(self.lstm_size, self.vocab_size)\n",
        "\n",
        "    def forward(self, x, prev_state):\n",
        "        # Pass through Embedding Layer\n",
        "        embedded = self.embedding(x)\n",
        "\n",
        "        # Pass through LSTM Layer\n",
        "        out, new_state = self.LSTM(embedded, prev_state)\n",
        "\n",
        "        # Pass through Fully Connected Layer to get output vocabulary size\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out, new_state\n",
        "\n",
        "    def init_state(self, batch_size):\n",
        "        # Initialize h_0 and c_0 to zeros for prediction\n",
        "        return (\n",
        "            torch.zeros(self.num_layers, batch_size, self.lstm_size).to(self.device),\n",
        "            torch.zeros(self.num_layers, batch_size, self.lstm_size).to(self.device)\n",
        "        )"
      ],
      "metadata": {
        "id": "hseJegwZbASH"
      },
      "id": "hseJegwZbASH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model and store it to device.\n",
        "lstm = LSTM(test_dat).to(device)\n",
        "lstm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yySMJvKZbBpC",
        "outputId": "e166355a-d540-4d81-ab0e-776a5090e17d"
      },
      "id": "yySMJvKZbBpC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (embedding): Embedding(39335, 256)\n",
              "  (LSTM): LSTM(256, 128, num_layers=2)\n",
              "  (fc): Linear(in_features=128, out_features=39335, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **A7-T2**"
      ],
      "metadata": {
        "id": "G1Is-VmPq6nt"
      },
      "id": "G1Is-VmPq6nt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training"
      ],
      "metadata": {
        "id": "nglBMg_w5pXs"
      },
      "id": "nglBMg_w5pXs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "074fdf1b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-05T19:29:21.147089Z",
          "iopub.status.busy": "2023-04-05T19:29:21.146762Z",
          "iopub.status.idle": "2023-04-05T19:29:21.159795Z",
          "shell.execute_reply": "2023-04-05T19:29:21.158718Z"
        },
        "papermill": {
          "duration": 0.021349,
          "end_time": "2023-04-05T19:29:21.162295",
          "exception": false,
          "start_time": "2023-04-05T19:29:21.140946",
          "status": "completed"
        },
        "tags": [],
        "id": "074fdf1b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def train(dataset, model, batch_size, epochs, simulate_batches=1):\n",
        "    '''\n",
        "    The training loop can simulate batches by splitting the batchs and accumulating losses.\n",
        "    Reduces GPU memory usage.\n",
        "    '''\n",
        "    batch_size = int(batch_size/simulate_batches)\n",
        "\n",
        "    #randomly splitting data to form a test and train dataloader\n",
        "    proportions = [.95, .05]\n",
        "    lengths = [int(p * len(test_dat)) for p in proportions]\n",
        "    lengths[-1] = len(test_dat) - sum(lengths[:-1])\n",
        "\n",
        "    train_set, test_set = random_split(dataset, lengths)\n",
        "    train_loader = DataLoader(train_set, batch_size = batch_size)\n",
        "    test_loader = DataLoader(test_set, batch_size = batch_size)\n",
        "\n",
        "    # using ADAM optimizer and CrossEntropyLoss for training\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # to convert some calculations to fp16 to make the training faster\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    # storing the losses for each batch and then for the epochs\n",
        "    losses = []\n",
        "    epoch_loss = []\n",
        "    validation_loss = []\n",
        "    validation_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # set model to training mode\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        print({ 'epoch': epoch})\n",
        "\n",
        "        for batch, (x,y) in tqdm(enumerate(train_loader), total =len(train_loader)):\n",
        "            # load input and expected output to device\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            #for fp16 calculations\n",
        "            with torch.cuda.amp.autocast(dtype=torch.float16):\n",
        "                # predict\n",
        "                y_pred, (a,b) = model(x, None)\n",
        "                #detach the hidden and cell states from gradient graph\n",
        "                a.detach()\n",
        "                b.detach()\n",
        "                #calculate loss\n",
        "                loss = criterion(y_pred.transpose(1,2), y)\n",
        "\n",
        "            # backprop step\n",
        "            scaler.scale(loss).backward()\n",
        "            # if batch%simulate_batches==0:\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "            # store the batch loss\n",
        "            epoch_loss.append(loss.item())\n",
        "        print('epoch : ', epoch, 'completed | ', 'loss :', loss.item())\n",
        "\n",
        "        # store the epoch losses\n",
        "        losses.append(epoch_loss)\n",
        "        epoch_loss = []\n",
        "\n",
        "        # put the mdoel on eval mode for testing\n",
        "        model.eval()\n",
        "\n",
        "        print(\"\\nCalculating validation loss for the epoch\")\n",
        "\n",
        "        # calculate the test losses\n",
        "        for (x,y) in tqdm(test_loader):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            y_pred, _ = model(x, None)\n",
        "            loss = criterion(y_pred.transpose(1,2), y)\n",
        "            validation_loss.append(loss.item())\n",
        "        validation_losses.append(validation_loss)\n",
        "        validation_loss = []\n",
        "\n",
        "        # saving each epoch model\n",
        "        os.makedirs(\"epoch_checkpoints\", exist_ok=True)\n",
        "        torch.save(model.state_dict(), \"epoch_checkpoints/epoch_\"+str(epoch)+\".pt\")\n",
        "\n",
        "    return (losses, validation_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37688c1b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-05T19:29:21.172389Z",
          "iopub.status.busy": "2023-04-05T19:29:21.172120Z",
          "iopub.status.idle": "2023-04-05T19:29:21.176759Z",
          "shell.execute_reply": "2023-04-05T19:29:21.175681Z"
        },
        "papermill": {
          "duration": 0.012329,
          "end_time": "2023-04-05T19:29:21.179150",
          "exception": false,
          "start_time": "2023-04-05T19:29:21.166821",
          "status": "completed"
        },
        "tags": [],
        "id": "37688c1b"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The model `lstm` was applied to the text dataset `text_dat`\n",
        "* No of epochs trained, `epochs = 5`\n",
        "* Batch Size considered by training, `batch_size = 128`"
      ],
      "metadata": {
        "id": "1mufXEVOp5Vv"
      },
      "id": "1mufXEVOp5Vv"
    },
    {
      "cell_type": "code",
      "source": [
        "losses = train(text_dat, lstm, 128, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dE5wygrxbH57",
        "outputId": "be1afa52-5d95-426a-f491-946a102f0e81"
      },
      "id": "dE5wygrxbH57",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-13-5368c597afc7>:24: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/11024 [00:00<?, ?it/s]<ipython-input-13-5368c597afc7>:44: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(dtype=torch.float16):\n",
            "100%|██████████| 11024/11024 [15:51<00:00, 11.59it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch :  0 completed |  loss : 5.565595626831055\n",
            "\n",
            "Calculating validation loss for the epoch\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 581/581 [00:30<00:00, 19.23it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 1}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 11024/11024 [15:51<00:00, 11.58it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch :  1 completed |  loss : 5.427110195159912\n",
            "\n",
            "Calculating validation loss for the epoch\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 581/581 [00:30<00:00, 19.18it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 2}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 11024/11024 [15:49<00:00, 11.61it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch :  2 completed |  loss : 5.362697601318359\n",
            "\n",
            "Calculating validation loss for the epoch\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 581/581 [00:30<00:00, 19.13it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 3}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11024/11024 [15:52<00:00, 11.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch :  3 completed |  loss : 5.32464075088501\n",
            "\n",
            "Calculating validation loss for the epoch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 581/581 [00:30<00:00, 19.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 4}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11024/11024 [15:49<00:00, 11.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch :  4 completed |  loss : 5.299858570098877\n",
            "\n",
            "Calculating validation loss for the epoch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 581/581 [00:30<00:00, 19.12it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Saving the trained model  `lstm` for future use.\n",
        "* Also the `losses` are saved in `.pkl` file"
      ],
      "metadata": {
        "id": "zc1E8YS4pQaI"
      },
      "id": "zc1E8YS4pQaI"
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the model\n",
        "torch.save(lstm.state_dict(), \"lstm_model.pt\")"
      ],
      "metadata": {
        "id": "3N0X04iobgOx"
      },
      "id": "3N0X04iobgOx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b5e80d4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-06T06:13:40.180315Z",
          "iopub.status.busy": "2023-04-06T06:13:40.179919Z",
          "iopub.status.idle": "2023-04-06T06:13:40.194169Z",
          "shell.execute_reply": "2023-04-06T06:13:40.193242Z"
        },
        "papermill": {
          "duration": 12.253215,
          "end_time": "2023-04-06T06:13:40.196303",
          "exception": false,
          "start_time": "2023-04-06T06:13:27.943088",
          "status": "completed"
        },
        "tags": [],
        "id": "9b5e80d4"
      },
      "outputs": [],
      "source": [
        "# Saving the losses\n",
        "with open(\"losses.pkl\",\"wb\") as f:\n",
        "    pickle.dump(losses,f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plotting the Error Graph"
      ],
      "metadata": {
        "id": "9wlDacl5vnn8"
      },
      "id": "9wlDacl5vnn8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4537a64",
      "metadata": {
        "id": "f4537a64"
      },
      "outputs": [],
      "source": [
        "with open(\"losses.pkl\", \"rb\") as f:\n",
        "    losses = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5b576c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "a5b576c2",
        "outputId": "0ae0696f-d04b-4ad9-ce80-14d1655d3925"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "validation = losses[1]\n",
        "avg_val = [np.mean(x) for x in validation]\n",
        "training = losses[0]\n",
        "avg = [np.mean(x) for x in training]\n",
        "\n",
        "plt.plot(range(5), avg)\n",
        "plt.plot(range(5), avg_val)\n",
        "plt.legend([\"training loss\", \"test loss\"], loc=\"upper right\")\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"loss\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The training and test loss decrease consistently with epochs, indicating that the model is learning effectively without signs of overfitting during the initial epochs.\n",
        "* The test loss is slightly lower than the training loss across epochs, suggesting a well-generalized model with no significant overfitting issues."
      ],
      "metadata": {
        "id": "qdcTQFL1Sa5m"
      },
      "id": "qdcTQFL1Sa5m"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **A8-T1**"
      ],
      "metadata": {
        "id": "KExjYzabv7jh"
      },
      "id": "KExjYzabv7jh"
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(dataset, model, text, max_words=100):\n",
        "    '''\n",
        "    A function to Predict the next few words given a seed.\n",
        "    The words will be generate till the end token </s> is reached or the max_words is reached.\n",
        "    '''\n",
        "    model.to('cpu').eval()\n",
        "\n",
        "    words = text.split(' ')\n",
        "    # initializing hidden and cell states\n",
        "    state_h, state_c = model.init_state(len(words))\n",
        "\n",
        "    # Move hidden states to CPU\n",
        "    state_h = state_h.to('cpu')\n",
        "    state_c = state_c.to('cpu')\n",
        "\n",
        "    for i in range(0, max_words):\n",
        "        x = torch.tensor([[dataset.word_to_idx[w] for w in words[i:]]])\n",
        "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "\n",
        "        last_word_logits = y_pred[0][-1]\n",
        "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
        "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "        words.append(dataset.idx_to_word[word_index])\n",
        "\n",
        "        if dataset.idx_to_word[word_index]==\"</s>\":\n",
        "            break\n",
        "\n",
        "    for i in range(15, len(words), 15):\n",
        "        words.insert(i, \"\\n\")\n",
        "\n",
        "    return \" \".join(words)"
      ],
      "metadata": {
        "id": "QEZKPqyMb21e"
      },
      "id": "QEZKPqyMb21e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = LSTM(text_dat)\n",
        "lstm.load_state_dict(torch.load(\"lstm_model.pt\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxE3J5OVbXlp",
        "outputId": "f8a5a748-4ea8-400d-a6c9-f54bb629a527"
      },
      "id": "xxE3J5OVbXlp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-41ae596dd9df>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  lstm.load_state_dict(torch.load(\"lstm_model_2.pt\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Abstract Generation\n",
        "\n",
        "* The `predict` function allows any length of seed text (`text`), as it dynamically converts the input words to indices and initializes the hidden states accordingly, ensuring the model can process sequences of varying lengths.\n",
        "* Starting from the provided seed, the function generates text iteratively, predicting one word at a time until either the `<end>` token (`</s>`) is reached or the `max_words` limit is hit, regardless of the initial seed size."
      ],
      "metadata": {
        "id": "KgfkdBFOFh2l"
      },
      "id": "KgfkdBFOFh2l"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Generated Abstracts 1 - 100 words"
      ],
      "metadata": {
        "id": "lD2BBT3S_JDn"
      },
      "id": "lD2BBT3S_JDn"
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict(text_dat, lstm, \"<s>\", max_words=100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tybXmZqI-41k",
        "outputId": "e045a606-ff1b-426b-bd29-51717eec6075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> is systematic manner the goals and dispersal by combining localized in mice the rights \n",
            " not detected and swat gates are accepted multichannel verifying protocols demographic and vegetables introduction \n",
            " of different randomly assigned to surroundings the therapeutic modalities and testing on this work \n",
            " explores perceptions of cases of obligate intracellular concentrations surpassing the advantage of review regarding \n",
            " surgical vaccination are spherical inclusions in clinical symptoms and middle school of broiler flocks \n",
            " with the relative to start of people start of the decrease risk of the \n",
            " interaction networks to the protein mir however the interactions are also been established collective investment and\n"
          ]
        }
      ],
      "id": "tybXmZqI-41k"
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict(test_dat, lstm, \"<s> there are number of newly described and emerging disease\", max_words=100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCPsc-ccn7_a",
        "outputId": "b4ec0633-1a12-4a1f-d48e-aa9ac9dec9c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> there is one number of newly described and emerging disease viral conclusions of using \n",
            " using the epidemic in this work combines perspective of proteins that kind of significant \n",
            " differences with multiple perspectives we characterize social and conjecture in the netherlands in this \n",
            " pandemic and inotropic links detected as interventions will have been disproportionate impact of mucin \n",
            " infected with those who are scarce in an outbreak and proteins can be carefully \n",
            " interpreted as an important approach is unclear conclusions while host cells were cited global \n",
            " influenza ha of pilgrims were detected in fecal was isolated but also present an \n",
            " acceptable for new insight to the treatment of today in official twin\n"
          ]
        }
      ],
      "id": "NCPsc-ccn7_a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Generated Abstracts 2 - 150 words"
      ],
      "metadata": {
        "id": "TcUoaCtjAOPc"
      },
      "id": "TcUoaCtjAOPc"
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict(test_dat, lstm, \"<s>\", max_words=150))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f40e9dd8-0d78-475b-8dc1-4b7b059636b7",
        "id": "OVUjjFekAIuf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> drug against neutralizing antibody response to the plaques such sectors the amount of people \n",
            " who receives equal in controlled directly increasing the sample matching the individual is characterized \n",
            " using extensive health research trends in diverse countries the various human animal welfare waters \n",
            " who were associated with the participants participated in addition certain reports coupled to travel \n",
            " ban from to to evaluate how populations for preterm birth during the model was \n",
            " slightly higher in the inflammation in groups were converted to human tracheal et structures \n",
            " and completely seen in clinical phases specifically compared to hosting the countries and residual \n",
            " severity implies the outbreak investigation has hardly the results patients were measured by the \n",
            " functions against and accessibility simplicity and infection or to have been made being admitted \n",
            " with circadian regimes distal units while maintaining topic in the rod in hospitalized children \n",
            " presenting in testing of genetic scaffold which was added and\n"
          ]
        }
      ],
      "id": "OVUjjFekAIuf"
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict(test_dat, lstm, \"<s> studies have suggested that excessive activation of the host immune system\", max_words=150))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHxh1hb4ouMx",
        "outputId": "443c2c42-4f30-4a62-f82a-bf586e2a180a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> studies have suggested that excessive activation of the host immune system are associated to \n",
            " relieve the service to higher scores for several messages in this paper we show \n",
            " that targeting have impacted by the age arrival after heating clinical syndrome and in \n",
            " the is exposed rats submitted to overcome it is gaining thoughtful patient infection overall \n",
            " respiratory syndrome which is proposed approach public health and to more and extraction the \n",
            " receiver operating under the community database with normal calves were stratified using the pandemic \n",
            " these transgenic chloroplasts in the mechanism underlying structural data model for people are the \n",
            " activity of and fatalities as at on pharmacy exploration we also reported and skills \n",
            " have been pandemic yet to include screening the advantages and governance challenges enabled the \n",
            " host immune responses of in less compromised decrease and psychological factors similar approach is \n",
            " given the group and ki by leveraging optimal cutoff of the pandemic and quarantine periodicity to assess scientific and decreased replication\n"
          ]
        }
      ],
      "id": "eHxh1hb4ouMx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Generated Abstracts 3 - 200 words"
      ],
      "metadata": {
        "id": "11U4GUNw_MHC"
      },
      "id": "11U4GUNw_MHC"
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict(text_dat, lstm, \"<s>\", max_words=200))"
      ],
      "metadata": {
        "id": "hDGJf1Vsin7G",
        "outputId": "fbb297bc-11d9-493f-b9ff-aad1b058a80d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "hDGJf1Vsin7G",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> although human cleavage of communication demand for data to address mortality rate of the \n",
            " beginning of to detect increased mortality level for bacteria the evolutionary effects indeed dentists \n",
            " who become cleavage of china at weeks followup time while affecting where treatment modalities \n",
            " like the threat via up to simulate and an has highlighted important when the \n",
            " age range low routine new member states use distribution we found that any one \n",
            " of the strains were evaluated in the most influential themes in family results were \n",
            " collected from case of the pandemic regular agriculture bats annotated form to interventions to \n",
            " enzymes including the pituitary agent in lung injury caused motivation for exposure to be \n",
            " better understanding of liver function and screening we use of epidemics can be possible \n",
            " cyclosporine separate nation using we describe both the normal images be found that this \n",
            " report the glycoproteins from nasal spray drying and comparison from to occur how many \n",
            " areas of on replacements alone first established virus and acute respiratory symptoms chest and \n",
            " adults developed an epidemiological analysis study aimed at median duration through chest images termed \n",
            " has negative conversion to counter any cell and through their clinical materials and chronic emergent and specific antiviral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict(test_dat, lstm, \"<s> pandemic\", max_words=200))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr1fNb3lpEl6",
        "outputId": "acc902c0-c256-40b2-a4f6-1fb2a7fd65a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> pandemic is simple transcription factor the thematic footprint of and the groups six dogs \n",
            " were and the course was produced by the infectious disease and according to avoid \n",
            " adaptation of ace is deceased the site of diagnostic performance of policies have two \n",
            " clinical status associated with acknowledgement the vasoconstriction immune responses toward converting enzyme for symptoms \n",
            " and discuss the presence of distinct from for pa the general public implementation of \n",
            " and later however large academic hospital at low titers per day during the heart \n",
            " disease and protein vector control group for all other countries to derive the main \n",
            " clusters in the following experimental results are accepting the ability in persistent reproductive number \n",
            " of synergies the protein contains motif containing new hosts and were reported in participants \n",
            " active against and hospital to the donors are relevant in complete spectrum of survey \n",
            " in this stage so that fidelity properties of the assessment of at nasal clinical \n",
            " similarity with inhaled by on swift damage remains versus sample collection of infections and \n",
            " analysis of disaster rate and carbohydrates and that the development of the archive bases \n",
            " of cells after the main cause health computer vision detailing an international research equipment indoors or lower when incorporated\n"
          ]
        }
      ],
      "id": "mr1fNb3lpEl6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Generated Abstract 4 - 500 words"
      ],
      "metadata": {
        "id": "15xykoD9_8K-"
      },
      "id": "15xykoD9_8K-"
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict(test_dat, lstm, \"<s>\", max_words=500))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57f84cc3-a882-44aa-f197-0d4dda2c1487",
        "id": "f17jbWZkAfGD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> to seeking to other our method by which is followed by reviewers that cells \n",
            " and concentration fibrinogen and then ps preparations and their loved ones this is usually \n",
            " come on consumer stores necessary considerable antiviral strategies to assess the patients serum values \n",
            " as and the years who knew we describe the matrix using the organs in \n",
            " the infection in neutralizing from influenza based approaches and to study was performed and \n",
            " assembly of reported percent of consensus sequence representations of calves used some four in \n",
            " providing information per thousand were intravenously with decreasing bias assessment of enteric virus uses \n",
            " media and controlling the genes are observed for analysis of cell surrogate for the \n",
            " interaction networks of where remained unclear since their personal protective role of health and \n",
            " microbial genotypes displayed more than two tissues and goats of infections journal journal individuals \n",
            " to be achieved in et results were excluded included articles from local health emergency \n",
            " propositions for each cohort when comparing acute infections it has recently to avoid contagion \n",
            " thousands of of an in children living cells use of tests we propose limited \n",
            " by deletion of in surgical abilities for furthermore histological report recurrent infections physical and \n",
            " observations and to study was evaluated results here we investigated the limited of selective \n",
            " chaperones in mice via we analyze large academic medical images we examine its utility \n",
            " of serious infection control however or between waveforms wind speed of the predicted adjuvants \n",
            " infection of clinical trials yet fit objectively in the perception in adolescents aged months \n",
            " which led to male predominance of english language deterministic model if they require sharing \n",
            " information to accomplish compared to improve the expansion from the level but we call \n",
            " blend and were included in one of the divergence in this category of the \n",
            " availability reviews and networks in the could not correct thus providing an urgent need \n",
            " to difficulty of dry cough respiratory virus treatment targeting changes in the pandemic emotional \n",
            " symptoms of virus transport components is urgent need for the role of or leading \n",
            " cause of attrition nationwide and environmental molecular docking based on chains and the rate \n",
            " but are two are guaranteed the quality between both methods this herein this is \n",
            " desirable parameter from data individual faecal but it happen to understanding of the morbidity \n",
            " although the first recognize that to reduce the potential species culminates in at having \n",
            " healthcare heuristics to screen structure and south financial cycle of the contribution studying the \n",
            " their by flow by variety of patients managed anonymously full circular email distributed under \n",
            " active against environmental friendly jamming schemes for the patients with to dispatch management care \n",
            " workers in pregnancies infections to the different scenarios that the transportation structures were treated \n",
            " in the feasibility of the transport problem generates responsible for conclusion the use of \n",
            " prematurity the trained as major role of the development incidence of the inclusion regulations in including the agents four complete resolution of the types cell mediated by the molecular mimicry this paper employs small intestine and safer management\n"
          ]
        }
      ],
      "id": "f17jbWZkAfGD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Generated Abstract 5 - 1000 words"
      ],
      "metadata": {
        "id": "SFoXIFpWAXps"
      },
      "id": "SFoXIFpWAXps"
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict(text_dat, lstm, \"<s>\", max_words=1000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFrUau4Biiyj",
        "outputId": "ad8a2b61-f1cc-479a-eaac-a9ff58659dc1"
      },
      "id": "rFrUau4Biiyj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> tuberculosis diseases that people several tissues from the intensive care and we use of \n",
            " different between common vestibular and who were treated with blood utilities for reasoning herein \n",
            " we demonstrate that the spread in the arterial ace remains unclear long care or \n",
            " the morbidity statistical analyses indicated microorganisms in cells that fever polio and simultaneously shared \n",
            " via antigen interestingly we review article is arrives as which are also provides key \n",
            " stakeholders of diseases caring for any cell fields within the other but lead to \n",
            " this case series of from the antiviral strategy improved public health conditions in defining \n",
            " the droplet nucleotide variations in this pandemic in improving the data submitted analyze the \n",
            " right anterior ischemia applicability of price location robust viral replication early outbreak to react \n",
            " to the cumulative but it impaired replication is the biological origin of setup to \n",
            " establish both comparisons in the investigation it provides an inhibitor of different clusters of \n",
            " therapy results conforming to experience with an environmental factors to reach public health ramifications \n",
            " of water forces and the convection toxic metabolites such as the recent development of \n",
            " is policies for neutralizing antibodies against mortality patients admitted for unambiguous controls for the \n",
            " peak compared with the pandemic it purpose of ace from the solution to march \n",
            " and severity and signaling in the serial electrocardiograms and of diversity of average by \n",
            " our understanding that accelerates both large numbers that although simple test were also lead \n",
            " to with more infectious diseases understanding of codes tailored to length of infected with \n",
            " they are carried out of masks for surveillance purposes as effective health insurance and \n",
            " length of position for and died of an acute respiratory syndrome infection control and \n",
            " developing data bank stably express their criteria zoom enrolment transmitting further clinical isolates and \n",
            " adenovirus even within major organ permeability requiring mechanical ventilation therapy initiation codon with the \n",
            " human respiratory virus pandemics as normalized saliva of tasks accurate dynamics namely constraints to \n",
            " use of the imperative to these class molecules it would be safe poultry farming \n",
            " practices of various aspects of massive losses these we collected among different factors for \n",
            " the significant of infection in order to institutional review the children present with the \n",
            " potential from to modulate host cells for was added to tables proportion in biopsies \n",
            " increased morbidity and mainly localized ventilation and manage have similar infection might be tested \n",
            " by mixed models the recent review discusses mathematical modeling results suggest predictions using in \n",
            " the development of heterogeneous and with case series people diagnosed education data and cells \n",
            " in randomized controlled table an array technology platforms nonetheless we identified in monophyletic fig \n",
            " and numerical simulations indicate that fulfill the highest size resulting in this corresponds to \n",
            " our approach should be their duties in patients as judged from these two classic \n",
            " estimate robots for other viral spike protein levels in patients with mild upper limb \n",
            " band and by the percolation reviews and development of pulmonary disease affecting resources in \n",
            " case prince and antivirals or magnetic authorship review is the probe flow rate of \n",
            " infected nodes conclusions the relative nucleotide high risk of the lower hemoglobin in the \n",
            " notion that have been important implications of rats are to mine spoil were elevated \n",
            " insulin within the response to penetrate to measure of the future challenges to in \n",
            " the newly emerging infectious disease is positive recruitment abilities to understand the basics level \n",
            " trauma clinics attitudes has become action showing targets led the light retina virus genomes \n",
            " from or less attention this role for the dependent molecules and virions providing timely \n",
            " outcome and fusion to have an analysis and systematic studies on but we found \n",
            " in particular promising functional recovery rate was exist in the full text combs reed \n",
            " army and predominated in oral in the virus changeover to give pairwise alignment the \n",
            " reasons studies done at this virus spread of antibodies into clinical severity of face \n",
            " much better than those indicated segmental spontaneous circulation die casein kinase cognate peptide and \n",
            " examined the diagnosis of sufferers the samples were patient care settings for the uncertainty \n",
            " surrounding tissue specimens collected from the national association between the neurological disorder and the \n",
            " corresponding direction of infection control of the goal of two loci measured by public \n",
            " approved and camels and presented to detect not directly boiled clients to participate in \n",
            " the netherlands and present tool development of secreting cells were mortality rate of was \n",
            " used to detect antibodies of salts and what data were verified by zaire this \n",
            " supported by two main relationships between harmless disease human results in bacteria that the \n",
            " setting of vaccine design and porcine growth tests passage of cardiovascular disease in several \n",
            " days to think the ocular pathogen that could be distinguished all but no relevant \n",
            " reagents separately to relate by affecting conducting research and of tryptophan kinase the time \n",
            " to extend to the delay or an operational question new fraud sales radius of \n",
            " the war at the gaps accounted for or scattered in computed tomography scans in \n",
            " different parameters that this microorganism platelet counts improve metal with new data fig and \n",
            " were identified yet little is taken into mice additive effect of the fraction sizes \n",
            " and knowledge on where caused by assay in the impact of the history study temporal differences were linked to modulate the number of life at primary outcome data to identify represent an opportunity to pathogens predispose physical activity and fragments and our study is not sufficient an expanding patient was faster than researchers using in creating an important question in stool periodic cap\n",
            " </s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **A8-T2**"
      ],
      "metadata": {
        "id": "9UTlT9E-AoRi"
      },
      "id": "9UTlT9E-AoRi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Discussion of the Results\n",
        "\n",
        "* The five abstracts generated by the LSTM model exhibit structural coherence but lack semantic meaning.\n",
        "\n",
        "##### **Observations:**\n",
        "1. **Structural Patterns:**  \n",
        "   The abstracts follow sentence-like structures with appropriate grammar and word order, but they lack logical coherence or meaningful connections between phrases.\n",
        "   \n",
        "2. **Repetitive and Incoherent Content:**  \n",
        "   Several generated abstracts contain repetitive patterns or incoherent combinations of scientific terms, indicating difficulty in maintaining context across long sequences.\n",
        "\n",
        "3. **Vocabulary Usage:**  \n",
        "   The abstracts include domain-specific terms (e.g., \"antibodies,\" \"infections,\" \"neutralizing\"), suggesting the model has learned some patterns from the COVID-19 dataset but struggles with semantic associations.\n",
        "\n",
        "##### **Potential Reasons for Sub-Optimal Results:**\n",
        "1. The dataset might contain noisy or inconsistent abstracts, leading to poor model learning.\n",
        "2. The current LSTM model may be too simple to capture the complexity of abstract generation.\n",
        "3. The model might be underfitted due to insufficient training epochs (`epochs = 5`, which is really less) or sequence length.  \n",
        "\n",
        "##### **Improvements:**\n",
        "1. Better results could have been generated by using a cleaner dataset, a char-level LSTM instead of word level, more epochs, reducing vocab size if it's word level, and not skipping possible training sequences as it has been implemented in the dataloader.\n",
        "2. One more possible improvement could be storing the state for the whole abstract instead of just keeping it for the sequences while training.\n",
        "3. A larger sequence length could also help to generate longer abstracts of better context.\n",
        "4. Increasing the number of training epochs could further fine-tune the model, potentially improving its performance in generating abstracts."
      ],
      "metadata": {
        "id": "tJLNMAdNBMfo"
      },
      "id": "tJLNMAdNBMfo"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "papermill": {
      "default_parameters": {},
      "duration": null,
      "end_time": null,
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-04-05T19:28:59.302004",
      "version": "2.4.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}